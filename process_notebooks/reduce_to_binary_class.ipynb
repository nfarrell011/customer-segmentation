{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce Multi-class Dataset to Binary Dataset  \n",
    "This notebook will modify our original multi-class dataset to a 2-class dataset.  \n",
    "This is in order to reduce our multi-class classification problem to a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up ```sys``` Path to Enable ```.py``` Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The working directory has been set to: /Users/nelsonfarrell/Documents/Northeastern/5220/final_project\n"
     ]
    }
   ],
   "source": [
    "path = Path.cwd()\n",
    "path_to_project_directory = path.parent\n",
    "sys.path.insert(1, str(path_to_project_directory))\n",
    "print(f\"The working directory has been set to: {str(path_to_project_directory)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ```.py``` Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_possible_binary_datasets(original_df:pd.DataFrame, label:str) -> dict:\n",
    "    \"\"\"\n",
    "    Reduces a multi-class data frame to a binary data frame\n",
    "\n",
    "    Args:\n",
    "        * original_df: (pd.DataFrame) - The original multiclass data frame.\n",
    "        * label: (str) - The column name of the label column.\n",
    "        \n",
    "    Returns:\n",
    "        * dict: A dictionary containing all possible 2 class data frames.\n",
    "    \"\"\"\n",
    "    segmentation_values = list(original_df[label].unique())\n",
    "    results = {}\n",
    "    for i in range(len(segmentation_values)):\n",
    "        for j in segmentation_values[i + 1:]:\n",
    "            filtered_df = original_df[(original_df[label] == segmentation_values[i]) | \n",
    "                                    (original_df[label] == j)]\n",
    "            label_1, label_2 = filtered_df[label].unique()[0], filtered_df[label].unique()[1]\n",
    "            filtered_df_name = f\"filtered_df_{label_1}_{label_2}\"\n",
    "            results[filtered_df_name] = filtered_df\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_folder_name = \"data/filtered_datasets\"\n",
    "path_to_original_data = \"../data/raw_from_kaggle/Train.csv\"\n",
    "label_col_name = \"Segmentation\"\n",
    "data_set_A_B = \"data_set_A_B.csv\"\n",
    "data_set_A_C = \"data_set_A_C.csv\"\n",
    "data_set_B_C = \"data_set_B_C.csv\"\n",
    "data_set_D_A = \"data_set_D_A.csv\"\n",
    "data_set_D_B = \"data_set_D_B.csv\"\n",
    "data_set_D_C = \"data_set_D_C.csv\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv(path_to_original_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate All Possible Binary Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = get_all_possible_binary_datasets(original_df, label_col_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Destination Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(str(path_to_project_directory), new_data_folder_name), exist_ok = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Binary Datasets as ```csv``` Files  \n",
    "There will be 6 binary datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtdered_df_list = [data_set_D_A, data_set_D_B, data_set_D_C, data_set_A_B, data_set_A_C, data_set_B_C]\n",
    "for key, dataset in zip(results_dict.keys(), filtdered_df_list):\n",
    "    df = results_dict[key]\n",
    "    df.to_csv(os.path.join(path_to_project_directory, new_data_folder_name, dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b31d6a8ecfd6b48ec0cf9da67896692b418c4a39f70d4f1a3880fdc530a94b5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
