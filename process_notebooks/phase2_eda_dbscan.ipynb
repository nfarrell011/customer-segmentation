{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing the Relationship of Target Classes Via ```DBSCAN```  \n",
    "This notebooks attempts to ascertain if there exists a latent number of classes in the target variable.\n",
    "This analysis has two primary motivations:\n",
    "1. If there are clearly less than 4 classes the overall complexity of the classification problem can be reduced.\n",
    "2. If it is determined that classes within the target have close relationships then the interpretation of the results\n",
    "and the recommendations could be impacted.\n",
    "\n",
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, TargetEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import DBSCAN\n",
    "import hdbscan.validity as dbcv_hdbscan\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.base import BaseEstimator, ClusterMixin\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Ignore warning related to computing validity index\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"invalid value encountered in scalar divide\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up ```sys``` Path to Enable ```.py``` Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The working directory has been set to: /Users/nelsonfarrell/Documents/Northeastern/5220/final_project\n"
     ]
    }
   ],
   "source": [
    "path = Path.cwd()\n",
    "path_to_project_directory = path.parent\n",
    "sys.path.insert(1, str(path_to_project_directory))\n",
    "print(f\"The working directory has been set to: {str(path_to_project_directory)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ```.py``` Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.phase1_utils import * "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_DBSCAN(cap_x, dim_reduction_algo = None, eps_list = [0.3, 0.5, 0.6, 0.75, 0.85, 1.0], min_samples_list = [5, 10, 20, 50, 100], distance_metric = \"euclidean\"):\n",
    "    \"\"\"\n",
    "    Performs GridSearch over DBSCAN hypers\n",
    "\n",
    "    Returns:\n",
    "        * results_dict\n",
    "    \"\"\"\n",
    "    # Results container\n",
    "    results_row_dict_list = []\n",
    "\n",
    "    # Hypers\n",
    "    eps_list = eps_list\n",
    "    min_samples_list = min_samples_list\n",
    "\n",
    "    # Get the Hopkins stat to assess cluster propensity\n",
    "    hopkins = get_hopkins(cap_x)\n",
    "\n",
    "    # Search loops\n",
    "    for eps in eps_list:\n",
    "        for min_sample in min_samples_list:\n",
    "\n",
    "            # This is used for validity index\n",
    "            dist_matrix = pairwise_distances(cap_x, metric = distance_metric)\n",
    "            dist_matrix = dist_matrix.astype(np.float64)\n",
    "\n",
    "            # Fit DBSCAN\n",
    "            dbscan = DBSCAN(\n",
    "                        eps = eps,\n",
    "                        min_samples = min_sample,\n",
    "                        metric = distance_metric,\n",
    "                        metric_params = None,\n",
    "                        algorithm = \"auto\",\n",
    "                        leaf_size = 30,\n",
    "                        p = None,\n",
    "                        n_jobs = None\n",
    "                    )\n",
    "            dbscan.fit(cap_x)\n",
    "\n",
    "            # This is for results tracking\n",
    "            clusters = np.unique(dbscan.labels_)\n",
    "            n_clusters = clusters[clusters != -1].shape[0]\n",
    "\n",
    "            # Compute validity index\n",
    "            try:\n",
    "                validity_index = dbcv_hdbscan.validity_index(X = dist_matrix, d = cap_x.shape[1] ,labels = dbscan.labels_, metric = 'precomputed')\n",
    "            except ValueError as e:\n",
    "                validity_index = np.nan\n",
    "\n",
    "            # Update results\n",
    "            results_row_dict_list.append({\n",
    "                        \"n_components\": cap_x.shape[1],\n",
    "                        \"n_clusters\": n_clusters,\n",
    "                        'eps': eps,\n",
    "                        \"min_samples\": min_sample,\n",
    "                        \"validity_index\": validity_index,\n",
    "                        \"hopkins_stat\": hopkins,\n",
    "                        \"dim_reduction_algo\": dim_reduction_algo\n",
    "                    })\n",
    "\n",
    "    return results_row_dict_list\n",
    "\n",
    "def grid_search_PCA(transformed_data, n_components = [2,3,4,5,6,8,10,15]):\n",
    "    \"\"\"\n",
    "    Iterates over PCA embeddings before DBSCAN gridsearch \n",
    "    \"\"\"\n",
    "    results_list = []\n",
    "    n_components = n_components\n",
    "    for n in n_components:\n",
    "        transfored_data_reduced = PCA(n_components = n).fit_transform(transformed_data)\n",
    "        results_row_dict_list = grid_search_DBSCAN(transfored_data_reduced, \"PCA\")\n",
    "        best_results = get_best_results(results_row_dict_list)\n",
    "        results_list.append(best_results)\n",
    "    return results_list\n",
    "\n",
    "def get_hopkins(cap_x):\n",
    "    '''\n",
    "    Calculates hopkin's statistic for a design matrix. Measures clustering propensity.\n",
    "        cap_h = sum(cap_x_nn_dist_list) / (sum(randomly_nn_dist_list) + sum(cap_x_nn_dist_list))\n",
    "\n",
    "    Parameters:\n",
    "        * cap_x (np.ndarray): design matrix\n",
    "    Returns:\n",
    "        * cap_h (float): hopkin's statistic value\n",
    "    '''\n",
    "    # seed random\n",
    "    np.random.seed(18)\n",
    "\n",
    "    # get uniformly randomley distributed data\n",
    "    data_max = cap_x.max(axis=0)\n",
    "    data_min = cap_x.min(axis=0)\n",
    "    random_dist_data = np.random.uniform(low=data_min, high=data_max, size=cap_x.shape)\n",
    "\n",
    "    ## null hypothesis: get nearest neighbor distance (random data)\n",
    "\n",
    "    # get list of nearest neighbors for random data\n",
    "    randomly_nn_dist_list = get_NN(random_dist_data)\n",
    "\n",
    "    # get nearest neighbor distance from embedding\n",
    "    cap_x_nn_dist_list = get_NN(cap_x)\n",
    "\n",
    "    # calculate hopkins\n",
    "    cap_h = sum(cap_x_nn_dist_list) / (sum(randomly_nn_dist_list) + sum(cap_x_nn_dist_list))\n",
    "\n",
    "    return cap_h\n",
    "\n",
    "def get_NN(cap_x):\n",
    "    '''\n",
    "    Returns nearest neighbors distances list.\n",
    "\n",
    "    Parameters:\n",
    "        * cap_x (np.ndarray): design matrix\n",
    "    Returns:\n",
    "        * nn_dist_list (list): list of nearest neighbors\n",
    "            \n",
    "    Documentation:\n",
    "        https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html\n",
    "    '''\n",
    "    # build the kdtree\n",
    "    kdt = KDTree(cap_x)\n",
    "\n",
    "    nn_dist_list = []\n",
    "    for i in range(cap_x.shape[0]):\n",
    "        dist, indices = kdt.query(cap_x[i, :].reshape(1, -1), 2)\n",
    "        nn_dist_list.append(dist[0, -1])\n",
    "\n",
    "    return nn_dist_list\n",
    "\n",
    "def get_best_results(results_row_dict_list):\n",
    "    results_df = pd.DataFrame(results_row_dict_list)\n",
    "    max_index = results_df[\"validity_index\"].idxmax()\n",
    "    return results_df.loc[max_index]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Set Up Data  \n",
    "This section generally follows the data setup portion of the linear regression flow."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data_directory = \"/data/data_splits/\"\n",
    "train_data_file_name = \"train_df.csv\"\n",
    "target_attr = \"Segmentation\"\n",
    "missingness_threshold = 0.20\n",
    "nominal_imputer_strategy = \"most_frequent\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Read In Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df = pd.read_csv(str(path_to_project_directory) + path_to_data_directory + train_data_file_name)\n",
    "train_df = orig_df.copy()\n",
    "del orig_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess Target Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train set PRE to dropping rows where the target missing: (6454, 12)\n",
      "The shape of train set POST to dropping rows where the target missing: (6454, 12)\n",
      "Number of rows dropped: 0\n"
     ]
    }
   ],
   "source": [
    "num_rows_train_df_pre = train_df.shape[0]\n",
    "print(f\"The shape of train set PRE to dropping rows where the target missing: {train_df.shape}\")\n",
    "train_df = train_df.dropna(subset = target_attr)\n",
    "num_rows_train_df_post = train_df.shape[0]\n",
    "print(f\"The shape of train set POST to dropping rows where the target missing: {train_df.shape}\")\n",
    "print(f\"Number of rows dropped: {num_rows_train_df_pre - num_rows_train_df_post}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Identify Attributes Above ```Missingness``` Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index missingness = 0.0\n",
      "ID missingness = 0.0\n",
      "Gender missingness = 0.0\n",
      "Ever_Married missingness = 0.017198636504493336\n",
      "Age missingness = 0.0\n",
      "Graduated missingness = 0.00914161760148745\n",
      "Profession missingness = 0.01642392314843508\n",
      "Work_Experience missingness = 0.10009296560272699\n",
      "Spending_Score missingness = 0.0\n",
      "Family_Size missingness = 0.040904865199876045\n",
      "Var_1 missingness = 0.009296560272699102\n",
      "Segmentation missingness = 0.0\n",
      "\n",
      "missingness_drop_list:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "missingness_results_dict = get_missingness(train_df, missingness_threshold)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Set Up ML Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "non_ML_attr:\n",
      "index\n",
      "ID\n",
      "\n",
      "*****************************\n",
      "ML_attr:\n",
      "Gender\n",
      "Ever_Married\n",
      "Age\n",
      "Graduated\n",
      "Profession\n",
      "Work_Experience\n",
      "Spending_Score\n",
      "Family_Size\n",
      "Var_1\n",
      "Segmentation\n",
      "\n",
      "*****************************\n",
      "non_ml_attribute_list:\n",
      "['index', 'ID']\n"
     ]
    }
   ],
   "source": [
    "non_ml_attributes_results = separate_unique_columns(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_attributes_drop_list = [target_attr] # Drop the target to perform clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These attributes will be ignored by the machine learning algorithm:\n",
      "\t1. index\n",
      "\t2. ID\n",
      "\t3. Segmentation\n"
     ]
    }
   ],
   "source": [
    "ml_ignore_list = missingness_results_dict[\"missingness_drop_list\"] \\\n",
    "                 + non_ml_attributes_results[\"non_ML_attr\"] \\\n",
    "                 + ml_attributes_drop_list\n",
    "\n",
    "print(f\"These attributes will be ignored by the machine learning algorithm:\")\n",
    "for idx, attr in enumerate(ml_ignore_list):\n",
    "    print(f\"\\t{idx + 1}. {attr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All attributes in the train set have been accounted for.\n",
      "\n",
      "ML Ignore List:\n",
      "1. index\n",
      "2. ID\n",
      "3. Segmentation\n",
      "\n",
      "Numerical Attributes:\n",
      "1. Age\n",
      "2. Work_Experience\n",
      "3. Family_Size\n",
      "\n",
      "Nominal Attributes:\n",
      "1. Gender\n",
      "2. Ever_Married\n",
      "3. Graduated\n",
      "4. Profession\n",
      "5. Spending_Score\n",
      "6. Var_1\n",
      "\n",
      "Total Number of ML Attributes: 9\n"
     ]
    }
   ],
   "source": [
    "# Set the numerical attributes list\n",
    "numerical_attr = [\"Age\", \"Work_Experience\", \"Family_Size\"]\n",
    "\n",
    "# Set the nominal attributes list\n",
    "nominal_attr = [attr for attr in train_df.columns if attr not in numerical_attr and attr not in ml_ignore_list]\n",
    "\n",
    "# Confirm all attributes are accounted for\n",
    "assert (train_df.shape[1] == len(numerical_attr) + len(nominal_attr) + len(ml_ignore_list))\n",
    "print(f\"All attributes in the train set have been accounted for.\")\n",
    "print()\n",
    "\n",
    "print(\"ML Ignore List:\")\n",
    "for idx, attr in enumerate(ml_ignore_list):\n",
    "    print(f\"{idx + 1}. {attr}\")\n",
    "print()\n",
    "\n",
    "print(\"Numerical Attributes:\")\n",
    "for idx, attr in enumerate(numerical_attr):\n",
    "    print(f\"{idx + 1}. {attr}\")\n",
    "print()\n",
    "\n",
    "print(\"Nominal Attributes:\")\n",
    "for idx, attr in enumerate(nominal_attr):\n",
    "    print(f\"{idx + 1}. {attr}\")\n",
    "print()\n",
    "\n",
    "print(f\"Total Number of ML Attributes: {len(nominal_attr) + len(numerical_attr)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Inspect the Cardinality of Nominal Attributes  \n",
    "\n",
    "This will inform the choice of nominal attribute encoder.  \n",
    "\n",
    "```TargetEncoding``` can reduce the number of resultant encoded attributes compared to ```OneHotEncoding```.  \n",
    "This becomes an issue when the nominal attributes have a large number of unique values.  \n",
    "\n",
    "However, in the case of a ```multiclass``` target, ```TargetEncoder``` uses 1 versus all  \n",
    "approach to computing the probability estimates.  \n",
    "\n",
    "Resultingly, this may not result fewer dimensions than the\n",
    "```OneHotEncoder```.\n",
    "\n",
    "Both encoders will be explored in the context of clustering with ```DBSCAN```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender            2\n",
       "Ever_Married      2\n",
       "Graduated         2\n",
       "Profession        9\n",
       "Spending_Score    3\n",
       "Var_1             7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nominal_cols_df = train_df[nominal_attr]\n",
    "nominal_cols_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nominal Encoded Features Post OneHotEncoding:\n",
      "\tIf dropping one col per attribute: 19\n",
      "\tIf NOT dropping one col per attribute: 28\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of Nominal Encoded Features Post OneHotEncoding:\")\n",
    "print(f\"\\tIf dropping one col per attribute: {nominal_cols_df.nunique().sum() - len(nominal_attr)}\")\n",
    "print(f\"\\tIf NOT dropping one col per attribute: {nominal_cols_df.nunique().sum()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## **OneHotEncoder**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline(\n",
    "                            steps = [(\"imputer\", SimpleImputer()),\n",
    "                                     (\"scaler\", StandardScaler())]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_transformer = Pipeline(\n",
    "                        steps = [(\"imputer\", SimpleImputer(strategy = nominal_imputer_strategy)),\n",
    "                                 (\"ohe\", OneHotEncoder())] \n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "                        transformers = [(\"nominal\", nominal_transformer, nominal_attr),\n",
    "                                        (\"numerical\", numerical_transformer, numerical_attr)\n",
    "                                ]\n",
    "                        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Transformed Data ~ OneHotEncoder\n",
    "This shows the output of the data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = preprocessor.fit_transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.695320</td>\n",
       "      <td>1.942754</td>\n",
       "      <td>-1.227022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.703982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.560068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.635337</td>\n",
       "      <td>-0.513120</td>\n",
       "      <td>0.773838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.264401</td>\n",
       "      <td>-0.820105</td>\n",
       "      <td>2.107745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.935250</td>\n",
       "      <td>1.942754</td>\n",
       "      <td>-1.227022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6449</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.995233</td>\n",
       "      <td>1.635769</td>\n",
       "      <td>-1.227022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.395407</td>\n",
       "      <td>-0.820105</td>\n",
       "      <td>-0.560068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6451</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.995233</td>\n",
       "      <td>1.021801</td>\n",
       "      <td>2.107745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6452</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.055215</td>\n",
       "      <td>-0.820105</td>\n",
       "      <td>-0.560068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6453</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.395407</td>\n",
       "      <td>-0.820105</td>\n",
       "      <td>0.106885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6454 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9   ...   18   19   20  \\\n",
       "0     1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1     0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       "2     1.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       "3     1.0  0.0  0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4     1.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "6449  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "6450  0.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "6451  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0   \n",
       "6452  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "6453  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "       21   22   23   24        25        26        27  \n",
       "0     0.0  0.0  1.0  0.0 -0.695320  1.942754 -1.227022  \n",
       "1     0.0  0.0  1.0  0.0  1.703982  0.000000 -0.560068  \n",
       "2     0.0  0.0  1.0  0.0 -0.635337 -0.513120  0.773838  \n",
       "3     0.0  0.0  1.0  0.0  0.264401 -0.820105  2.107745  \n",
       "4     0.0  0.0  0.0  1.0 -0.935250  1.942754 -1.227022  \n",
       "...   ...  ...  ...  ...       ...       ...       ...  \n",
       "6449  0.0  0.0  1.0  0.0 -0.995233  1.635769 -1.227022  \n",
       "6450  0.0  0.0  1.0  0.0 -0.395407 -0.820105 -0.560068  \n",
       "6451  1.0  0.0  0.0  0.0 -0.995233  1.021801  2.107745  \n",
       "6452  0.0  0.0  1.0  0.0 -1.055215 -0.820105 -0.560068  \n",
       "6453  0.0  0.0  1.0  0.0 -0.395407 -0.820105  0.106885  \n",
       "\n",
       "[6454 rows x 28 columns]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of attrinutes after OneHotEncoding: 28\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of attrinutes after OneHotEncoding: {transformed_data.shape[1] + 1}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Gridsearch over ```DBSCAN``` with ```OneHotEncoder```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nelsonfarrell/miniconda3/envs/conda_usml_env/lib/python3.12/site-packages/hdbscan/validity.py:33: RuntimeWarning: invalid value encountered in divide\n",
      "  result /= distance_matrix.shape[0] - 1\n"
     ]
    }
   ],
   "source": [
    "results_row_dict_list = grid_search_DBSCAN(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = get_best_results(results_row_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>eps</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>validity_index</th>\n",
       "      <th>hopkins_stat</th>\n",
       "      <th>dim_reduction_algo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>28</td>\n",
       "      <td>140</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5</td>\n",
       "      <td>0.297498</td>\n",
       "      <td>0.241446</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_components n_clusters   eps min_samples validity_index hopkins_stat  \\\n",
       "20           28        140  0.85           5       0.297498     0.241446   \n",
       "\n",
       "   dim_reduction_algo  \n",
       "20               None  "
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(best_results).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction with ```PCA``` ~ ```OneHotEncoding```\n",
    "This cell performs a gridsearch over DBSCAN hypers after dimenstionality reduction with PCA.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nelsonfarrell/miniconda3/envs/conda_usml_env/lib/python3.12/site-packages/hdbscan/validity.py:33: RuntimeWarning: invalid value encountered in divide\n",
      "  result /= distance_matrix.shape[0] - 1\n",
      "/Users/nelsonfarrell/miniconda3/envs/conda_usml_env/lib/python3.12/site-packages/hdbscan/validity.py:33: RuntimeWarning: invalid value encountered in divide\n",
      "  result /= distance_matrix.shape[0] - 1\n"
     ]
    }
   ],
   "source": [
    "results_list = grid_search_PCA(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>eps</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>validity_index</th>\n",
       "      <th>hopkins_stat</th>\n",
       "      <th>dim_reduction_algo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>50</td>\n",
       "      <td>-0.563148</td>\n",
       "      <td>0.385945</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.007134</td>\n",
       "      <td>0.291766</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.30</td>\n",
       "      <td>50</td>\n",
       "      <td>0.035080</td>\n",
       "      <td>0.251862</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.60</td>\n",
       "      <td>100</td>\n",
       "      <td>0.078419</td>\n",
       "      <td>0.221127</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>175</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.086437</td>\n",
       "      <td>0.201093</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>199</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.190038</td>\n",
       "      <td>0.174074</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>199</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.184547</td>\n",
       "      <td>0.163541</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>165</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.179938</td>\n",
       "      <td>0.166704</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_components  n_clusters   eps  min_samples  validity_index  hopkins_stat  \\\n",
       "3              2           2  0.30           50       -0.563148      0.385945   \n",
       "16             3           2  0.75           10       -0.007134      0.291766   \n",
       "3              4           5  0.30           50        0.035080      0.251862   \n",
       "14             5           5  0.60          100        0.078419      0.221127   \n",
       "0              6         175  0.30            5        0.086437      0.201093   \n",
       "5              8         199  0.50            5        0.190038      0.174074   \n",
       "5             10         199  0.50            5        0.184547      0.163541   \n",
       "5             15         165  0.50            5        0.179938      0.166704   \n",
       "\n",
       "   dim_reduction_algo  \n",
       "3                 PCA  \n",
       "16                PCA  \n",
       "3                 PCA  \n",
       "14                PCA  \n",
       "0                 PCA  \n",
       "5                 PCA  \n",
       "5                 PCA  \n",
       "5                 PCA  "
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## **Target Encoder**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Nominal Transformer ~ ```TargetEncoder```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap out OneHotEncoder() for TargetEncoder()\n",
    "nominal_transformer = Pipeline(\n",
    "                        steps = [(\"imputer\", SimpleImputer(strategy = nominal_imputer_strategy)),\n",
    "                                 (\"te\", TargetEncoder(target_type = \"multiclass\"))]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "                        transformers = [(\"nominal\", nominal_transformer, nominal_attr),\n",
    "                                        (\"numerical\", numerical_transformer, numerical_attr)\n",
    "                                ]\n",
    "                        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Transformed Data ~ ```TargetEncoder```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = preprocessor.fit_transform(train_df, train_df[target_attr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.239006</td>\n",
       "      <td>0.239415</td>\n",
       "      <td>0.254352</td>\n",
       "      <td>0.267226</td>\n",
       "      <td>0.247622</td>\n",
       "      <td>0.142614</td>\n",
       "      <td>0.124558</td>\n",
       "      <td>0.485146</td>\n",
       "      <td>0.247225</td>\n",
       "      <td>0.264785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178241</td>\n",
       "      <td>0.137787</td>\n",
       "      <td>0.406503</td>\n",
       "      <td>0.231660</td>\n",
       "      <td>0.234614</td>\n",
       "      <td>0.287264</td>\n",
       "      <td>0.246459</td>\n",
       "      <td>-0.695320</td>\n",
       "      <td>1.942754</td>\n",
       "      <td>-1.227022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.244318</td>\n",
       "      <td>0.222659</td>\n",
       "      <td>0.239348</td>\n",
       "      <td>0.293674</td>\n",
       "      <td>0.244997</td>\n",
       "      <td>0.285648</td>\n",
       "      <td>0.329535</td>\n",
       "      <td>0.139795</td>\n",
       "      <td>0.245911</td>\n",
       "      <td>0.271815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293919</td>\n",
       "      <td>0.460150</td>\n",
       "      <td>0.069784</td>\n",
       "      <td>0.230706</td>\n",
       "      <td>0.236840</td>\n",
       "      <td>0.287121</td>\n",
       "      <td>0.245331</td>\n",
       "      <td>1.703982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.560068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.239006</td>\n",
       "      <td>0.239415</td>\n",
       "      <td>0.254352</td>\n",
       "      <td>0.267226</td>\n",
       "      <td>0.247622</td>\n",
       "      <td>0.142614</td>\n",
       "      <td>0.124558</td>\n",
       "      <td>0.485146</td>\n",
       "      <td>0.247225</td>\n",
       "      <td>0.264785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178241</td>\n",
       "      <td>0.137787</td>\n",
       "      <td>0.406503</td>\n",
       "      <td>0.231660</td>\n",
       "      <td>0.234614</td>\n",
       "      <td>0.287264</td>\n",
       "      <td>0.246459</td>\n",
       "      <td>-0.635337</td>\n",
       "      <td>-0.513120</td>\n",
       "      <td>0.773838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.248826</td>\n",
       "      <td>0.234340</td>\n",
       "      <td>0.252233</td>\n",
       "      <td>0.264600</td>\n",
       "      <td>0.246917</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>0.328650</td>\n",
       "      <td>0.138249</td>\n",
       "      <td>0.244172</td>\n",
       "      <td>0.267165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286911</td>\n",
       "      <td>0.460818</td>\n",
       "      <td>0.071597</td>\n",
       "      <td>0.231177</td>\n",
       "      <td>0.234383</td>\n",
       "      <td>0.285743</td>\n",
       "      <td>0.248695</td>\n",
       "      <td>0.264401</td>\n",
       "      <td>-0.820105</td>\n",
       "      <td>2.107745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.248826</td>\n",
       "      <td>0.234340</td>\n",
       "      <td>0.252233</td>\n",
       "      <td>0.264600</td>\n",
       "      <td>0.246917</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>0.328650</td>\n",
       "      <td>0.138249</td>\n",
       "      <td>0.244876</td>\n",
       "      <td>0.167131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185352</td>\n",
       "      <td>0.134145</td>\n",
       "      <td>0.404562</td>\n",
       "      <td>0.240341</td>\n",
       "      <td>0.240231</td>\n",
       "      <td>0.209543</td>\n",
       "      <td>0.309841</td>\n",
       "      <td>-0.935250</td>\n",
       "      <td>1.942754</td>\n",
       "      <td>-1.227022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6449</th>\n",
       "      <td>0.239006</td>\n",
       "      <td>0.239415</td>\n",
       "      <td>0.254352</td>\n",
       "      <td>0.267226</td>\n",
       "      <td>0.247622</td>\n",
       "      <td>0.142614</td>\n",
       "      <td>0.124558</td>\n",
       "      <td>0.485146</td>\n",
       "      <td>0.240106</td>\n",
       "      <td>0.171899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178241</td>\n",
       "      <td>0.137787</td>\n",
       "      <td>0.406503</td>\n",
       "      <td>0.231660</td>\n",
       "      <td>0.234614</td>\n",
       "      <td>0.287264</td>\n",
       "      <td>0.246459</td>\n",
       "      <td>-0.995233</td>\n",
       "      <td>1.635769</td>\n",
       "      <td>-1.227022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>0.244318</td>\n",
       "      <td>0.222659</td>\n",
       "      <td>0.239348</td>\n",
       "      <td>0.293674</td>\n",
       "      <td>0.244068</td>\n",
       "      <td>0.146760</td>\n",
       "      <td>0.116257</td>\n",
       "      <td>0.492851</td>\n",
       "      <td>0.245911</td>\n",
       "      <td>0.271815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185887</td>\n",
       "      <td>0.129075</td>\n",
       "      <td>0.407014</td>\n",
       "      <td>0.230706</td>\n",
       "      <td>0.236840</td>\n",
       "      <td>0.287121</td>\n",
       "      <td>0.245331</td>\n",
       "      <td>-0.395407</td>\n",
       "      <td>-0.820105</td>\n",
       "      <td>-0.560068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6451</th>\n",
       "      <td>0.249151</td>\n",
       "      <td>0.235591</td>\n",
       "      <td>0.251692</td>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.246758</td>\n",
       "      <td>0.146452</td>\n",
       "      <td>0.118133</td>\n",
       "      <td>0.488595</td>\n",
       "      <td>0.237799</td>\n",
       "      <td>0.170629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181861</td>\n",
       "      <td>0.131661</td>\n",
       "      <td>0.405488</td>\n",
       "      <td>0.309035</td>\n",
       "      <td>0.210477</td>\n",
       "      <td>0.088633</td>\n",
       "      <td>0.391683</td>\n",
       "      <td>-0.995233</td>\n",
       "      <td>1.021801</td>\n",
       "      <td>2.107745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6452</th>\n",
       "      <td>0.240458</td>\n",
       "      <td>0.225831</td>\n",
       "      <td>0.237962</td>\n",
       "      <td>0.295749</td>\n",
       "      <td>0.246758</td>\n",
       "      <td>0.146452</td>\n",
       "      <td>0.118133</td>\n",
       "      <td>0.488595</td>\n",
       "      <td>0.237799</td>\n",
       "      <td>0.170629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181861</td>\n",
       "      <td>0.131661</td>\n",
       "      <td>0.405488</td>\n",
       "      <td>0.232698</td>\n",
       "      <td>0.235345</td>\n",
       "      <td>0.285406</td>\n",
       "      <td>0.246548</td>\n",
       "      <td>-1.055215</td>\n",
       "      <td>-0.820105</td>\n",
       "      <td>-0.560068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6453</th>\n",
       "      <td>0.239006</td>\n",
       "      <td>0.239415</td>\n",
       "      <td>0.254352</td>\n",
       "      <td>0.267226</td>\n",
       "      <td>0.247622</td>\n",
       "      <td>0.142614</td>\n",
       "      <td>0.124558</td>\n",
       "      <td>0.485146</td>\n",
       "      <td>0.247225</td>\n",
       "      <td>0.264785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178241</td>\n",
       "      <td>0.137787</td>\n",
       "      <td>0.406503</td>\n",
       "      <td>0.231660</td>\n",
       "      <td>0.234614</td>\n",
       "      <td>0.287264</td>\n",
       "      <td>0.246459</td>\n",
       "      <td>-0.395407</td>\n",
       "      <td>-0.820105</td>\n",
       "      <td>0.106885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6454 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.239006  0.239415  0.254352  0.267226  0.247622  0.142614  0.124558   \n",
       "1     0.244318  0.222659  0.239348  0.293674  0.244997  0.285648  0.329535   \n",
       "2     0.239006  0.239415  0.254352  0.267226  0.247622  0.142614  0.124558   \n",
       "3     0.248826  0.234340  0.252233  0.264600  0.246917  0.286157  0.328650   \n",
       "4     0.248826  0.234340  0.252233  0.264600  0.246917  0.286157  0.328650   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6449  0.239006  0.239415  0.254352  0.267226  0.247622  0.142614  0.124558   \n",
       "6450  0.244318  0.222659  0.239348  0.293674  0.244068  0.146760  0.116257   \n",
       "6451  0.249151  0.235591  0.251692  0.263566  0.246758  0.146452  0.118133   \n",
       "6452  0.240458  0.225831  0.237962  0.295749  0.246758  0.146452  0.118133   \n",
       "6453  0.239006  0.239415  0.254352  0.267226  0.247622  0.142614  0.124558   \n",
       "\n",
       "            7         8         9   ...        17        18        19  \\\n",
       "0     0.485146  0.247225  0.264785  ...  0.178241  0.137787  0.406503   \n",
       "1     0.139795  0.245911  0.271815  ...  0.293919  0.460150  0.069784   \n",
       "2     0.485146  0.247225  0.264785  ...  0.178241  0.137787  0.406503   \n",
       "3     0.138249  0.244172  0.267165  ...  0.286911  0.460818  0.071597   \n",
       "4     0.138249  0.244876  0.167131  ...  0.185352  0.134145  0.404562   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6449  0.485146  0.240106  0.171899  ...  0.178241  0.137787  0.406503   \n",
       "6450  0.492851  0.245911  0.271815  ...  0.185887  0.129075  0.407014   \n",
       "6451  0.488595  0.237799  0.170629  ...  0.181861  0.131661  0.405488   \n",
       "6452  0.488595  0.237799  0.170629  ...  0.181861  0.131661  0.405488   \n",
       "6453  0.485146  0.247225  0.264785  ...  0.178241  0.137787  0.406503   \n",
       "\n",
       "            20        21        22        23        24        25        26  \n",
       "0     0.231660  0.234614  0.287264  0.246459 -0.695320  1.942754 -1.227022  \n",
       "1     0.230706  0.236840  0.287121  0.245331  1.703982  0.000000 -0.560068  \n",
       "2     0.231660  0.234614  0.287264  0.246459 -0.635337 -0.513120  0.773838  \n",
       "3     0.231177  0.234383  0.285743  0.248695  0.264401 -0.820105  2.107745  \n",
       "4     0.240341  0.240231  0.209543  0.309841 -0.935250  1.942754 -1.227022  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6449  0.231660  0.234614  0.287264  0.246459 -0.995233  1.635769 -1.227022  \n",
       "6450  0.230706  0.236840  0.287121  0.245331 -0.395407 -0.820105 -0.560068  \n",
       "6451  0.309035  0.210477  0.088633  0.391683 -0.995233  1.021801  2.107745  \n",
       "6452  0.232698  0.235345  0.285406  0.246548 -1.055215 -0.820105 -0.560068  \n",
       "6453  0.231660  0.234614  0.287264  0.246459 -0.395407 -0.820105  0.106885  \n",
       "\n",
       "[6454 rows x 27 columns]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of attributes after TargerEncoding: 28\n"
     ]
    }
   ],
   "source": [
    "print(f\"The number of attributes after TargerEncoding: {transformed_data.shape[1] + 1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Gridsearch over ```DBSCAN``` with ```TargetEncoder```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_row_dict_list = grid_search_DBSCAN(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = get_best_results(results_row_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>eps</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>validity_index</th>\n",
       "      <th>hopkins_stat</th>\n",
       "      <th>dim_reduction_algo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>192</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.149299</td>\n",
       "      <td>0.291058</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_components n_clusters  eps min_samples validity_index hopkins_stat  \\\n",
       "0           27        192  0.3           5       0.149299     0.291058   \n",
       "\n",
       "  dim_reduction_algo  \n",
       "0               None  "
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(best_results).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction with ```PCA``` ~ ```TargetEncoder```  \n",
    "This cell performs a gridsearch over DBSCAN hypers after dimenstionality reduction with PCA.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nelsonfarrell/miniconda3/envs/conda_usml_env/lib/python3.12/site-packages/hdbscan/validity.py:33: RuntimeWarning: invalid value encountered in divide\n",
      "  result /= distance_matrix.shape[0] - 1\n",
      "/Users/nelsonfarrell/miniconda3/envs/conda_usml_env/lib/python3.12/site-packages/hdbscan/validity.py:33: RuntimeWarning: invalid value encountered in divide\n",
      "  result /= distance_matrix.shape[0] - 1\n"
     ]
    }
   ],
   "source": [
    "results_list = grid_search_PCA(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>eps</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>validity_index</th>\n",
       "      <th>hopkins_stat</th>\n",
       "      <th>dim_reduction_algo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.261348</td>\n",
       "      <td>0.283198</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.289595</td>\n",
       "      <td>0.139877</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.038434</td>\n",
       "      <td>0.186949</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>0.039539</td>\n",
       "      <td>0.188164</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>87</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.058741</td>\n",
       "      <td>0.196174</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.123247</td>\n",
       "      <td>0.193594</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>187</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.122423</td>\n",
       "      <td>0.213409</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>192</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.140284</td>\n",
       "      <td>0.218795</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_components  n_clusters  eps  min_samples  validity_index  hopkins_stat  \\\n",
       "0              2           2  0.3            5       -0.261348      0.283198   \n",
       "2              3          11  0.3           20        0.289595      0.139877   \n",
       "3              4          14  0.3           50        0.038434      0.186949   \n",
       "14             5           6  0.6          100        0.039539      0.188164   \n",
       "1              6          87  0.3           10        0.058741      0.196174   \n",
       "9              8           6  0.5          100        0.123247      0.193594   \n",
       "0             10         187  0.3            5        0.122423      0.213409   \n",
       "0             15         192  0.3            5        0.140284      0.218795   \n",
       "\n",
       "   dim_reduction_algo  \n",
       "0                 PCA  \n",
       "2                 PCA  \n",
       "3                 PCA  \n",
       "14                PCA  \n",
       "1                 PCA  \n",
       "9                 PCA  \n",
       "0                 PCA  \n",
       "0                 PCA  "
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_usml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 20:54:21) [Clang 16.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da4cd8f0634bb089af8a080791cb3057e8ab3f308fd22cb7297c73023f3c5013"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
