{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing the Relationship of Target Classes Via ```DBSCAN```  \n",
    "This notebooks attempts to ascertain if there exists a latent number of classes in the target variable.\n",
    "This analysis has two primary motivations:\n",
    "1. If there are clearly less than 4 classes the overall complexity of the classification problem can be reduced.\n",
    "2. If it is determined that classes within the target have close relationships then the interpretation of the results\n",
    "and the recommendations could be impacted."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, TargetEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import DBSCAN\n",
    "import hdbscan.validity as dbcv_hdbscan\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.base import BaseEstimator, ClusterMixin\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Ignore invalid value encountered in scalar divide warning\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"invalid value encountered in scalar divide\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up ```sys``` Path to Enable ```.py``` Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The working directory has been set to: /Users/nelsonfarrell/Documents/Northeastern/5220/final_project\n"
     ]
    }
   ],
   "source": [
    "path = Path.cwd()\n",
    "path_to_project_directory = path.parent\n",
    "sys.path.insert(1, str(path_to_project_directory))\n",
    "print(f\"The working directory has been set to: {str(path_to_project_directory)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.phase1_utils import * "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_DBSCAN(cap_x, dim_reduction_algo = None, eps_list = [0.3, 0.5, 0.6, 0.75, 0.85, 1.0], min_samples_list = [5, 10, 20, 50, 100], distance_metric = \"euclidean\"):\n",
    "    \"\"\"\n",
    "    Performs GridSearch over DBSCAN hypers\n",
    "\n",
    "    Returns:\n",
    "        * results_dict\n",
    "    \"\"\"\n",
    "    # Results container\n",
    "    results_row_dict_list = []\n",
    "\n",
    "    # Hypers\n",
    "    eps_list = eps_list\n",
    "    min_samples_list = min_samples_list\n",
    "\n",
    "    # Get the Hopkins stat to assess cluster propensity\n",
    "    hopkins = get_hopkins(cap_x)\n",
    "\n",
    "    # Search loops\n",
    "    for eps in eps_list:\n",
    "        for min_sample in min_samples_list:\n",
    "\n",
    "            # This is used for validity index\n",
    "            dist_matrix = pairwise_distances(cap_x, metric = distance_metric)\n",
    "            dist_matrix = dist_matrix.astype(np.float64)\n",
    "\n",
    "            # Fit DBSCAN\n",
    "            dbscan = DBSCAN(\n",
    "                        eps = eps,\n",
    "                        min_samples = min_sample,\n",
    "                        metric = distance_metric,\n",
    "                        metric_params = None,\n",
    "                        algorithm = \"auto\",\n",
    "                        leaf_size = 30,\n",
    "                        p = None,\n",
    "                        n_jobs = None\n",
    "                    )\n",
    "            dbscan.fit(cap_x)\n",
    "\n",
    "            # This is for results tracking\n",
    "            clusters = np.unique(dbscan.labels_)\n",
    "            n_clusters = clusters[clusters != -1].shape[0]\n",
    "\n",
    "            # Compute validity index\n",
    "            try:\n",
    "                validity_index = dbcv_hdbscan.validity_index(X = dist_matrix, d = cap_x.shape[1] ,labels = dbscan.labels_, metric = 'precomputed')\n",
    "            except ValueError as e:\n",
    "                validity_index = np.nan\n",
    "\n",
    "            # Update results\n",
    "            results_row_dict_list.append({\n",
    "                        \"n_components\": cap_x.shape[1],\n",
    "                        \"n_clusters\": n_clusters,\n",
    "                        'eps': eps,\n",
    "                        \"min_samples\": min_sample,\n",
    "                        \"validity_index\": validity_index,\n",
    "                        \"hopkins_stat\": hopkins,\n",
    "                        \"dim_reduction_algo\": dim_reduction_algo\n",
    "                    })\n",
    "\n",
    "    return results_row_dict_list\n",
    "\n",
    "def grid_search_PCA(transformed_data, n_components = [2,3,4,5,6,8,10,15]):\n",
    "    \"\"\"\n",
    "    Iterates over PCA embeddings before DBSCAN gridsearch \n",
    "    \"\"\"\n",
    "    results_list = []\n",
    "    n_components = n_components\n",
    "    for n in n_components:\n",
    "        transfored_data_reduced = PCA(n_components = n).fit_transform(transformed_data)\n",
    "        results_row_dict_list = grid_search_DBSCAN(transfored_data_reduced)\n",
    "        best_results = get_best_results(results_row_dict_list)\n",
    "        results_list.append(best_results)\n",
    "    return results_list\n",
    "\n",
    "def get_hopkins(cap_x):\n",
    "    '''\n",
    "    Calculates hopkin's statistic for a design matrix. Measures clustering propensity.\n",
    "        cap_h = sum(cap_x_nn_dist_list) / (sum(randomly_nn_dist_list) + sum(cap_x_nn_dist_list))\n",
    "\n",
    "    Parameters:\n",
    "        * cap_x (np.ndarray): design matrix\n",
    "    Returns:\n",
    "        * cap_h (float): hopkin's statistic value\n",
    "    '''\n",
    "    # seed random\n",
    "    np.random.seed(18)\n",
    "\n",
    "    # get uniformly randomley distributed data\n",
    "    data_max = cap_x.max(axis=0)\n",
    "    data_min = cap_x.min(axis=0)\n",
    "    random_dist_data = np.random.uniform(low=data_min, high=data_max, size=cap_x.shape)\n",
    "\n",
    "    ## null hypothesis: get nearest neighbor distance (random data)\n",
    "\n",
    "    # get list of nearest neighbors for random data\n",
    "    randomly_nn_dist_list = get_NN(random_dist_data)\n",
    "\n",
    "    # get nearest neighbor distance from embedding\n",
    "    cap_x_nn_dist_list = get_NN(cap_x)\n",
    "\n",
    "    # calculate hopkins\n",
    "    cap_h = sum(cap_x_nn_dist_list) / (sum(randomly_nn_dist_list) + sum(cap_x_nn_dist_list))\n",
    "\n",
    "    return cap_h\n",
    "\n",
    "def get_NN(cap_x):\n",
    "    '''\n",
    "    Returns nearest neighbors distances list.\n",
    "\n",
    "    Parameters:\n",
    "        * cap_x (np.ndarray): design matrix\n",
    "    Returns:\n",
    "        * nn_dist_list (list): list of nearest neighbors\n",
    "            \n",
    "    Documentation:\n",
    "        https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html\n",
    "    '''\n",
    "    # build the kdtree\n",
    "    kdt = KDTree(cap_x)\n",
    "\n",
    "    nn_dist_list = []\n",
    "    for i in range(cap_x.shape[0]):\n",
    "        dist, indices = kdt.query(cap_x[i, :].reshape(1, -1), 2)\n",
    "        nn_dist_list.append(dist[0, -1])\n",
    "\n",
    "    return nn_dist_list\n",
    "\n",
    "def get_best_results(results_row_dict_list):\n",
    "    results_df = pd.DataFrame(results_row_dict_list)\n",
    "    max_index = results_df[\"validity_index\"].idxmax()\n",
    "    return results_df.loc[max_index]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data_directory = \"/data/data_splits/\"\n",
    "train_data_file_name = \"train_df.csv\"\n",
    "target_attr = \"Segmentation\"\n",
    "missingness_threshold = 0.20\n",
    "nominal_imputer_strategy = \"most_frequent\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Read In Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df = pd.read_csv(str(path_to_project_directory) + path_to_data_directory + train_data_file_name)\n",
    "train_df = orig_df.copy()\n",
    "del orig_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess Target Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train set PRE to dropping rows where the target missing: (6454, 12)\n",
      "The shape of train set POST to dropping rows where the target missing: (6454, 12)\n",
      "Number of rows dropped: 0\n"
     ]
    }
   ],
   "source": [
    "num_rows_train_df_pre = train_df.shape[0]\n",
    "print(f\"The shape of train set PRE to dropping rows where the target missing: {train_df.shape}\")\n",
    "train_df = train_df.dropna(subset = target_attr)\n",
    "num_rows_train_df_post = train_df.shape[0]\n",
    "print(f\"The shape of train set POST to dropping rows where the target missing: {train_df.shape}\")\n",
    "print(f\"Number of rows dropped: {num_rows_train_df_pre - num_rows_train_df_post}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Identify Attributes Above ```Missingness``` Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index missingness = 0.0\n",
      "ID missingness = 0.0\n",
      "Gender missingness = 0.0\n",
      "Ever_Married missingness = 0.017198636504493336\n",
      "Age missingness = 0.0\n",
      "Graduated missingness = 0.00914161760148745\n",
      "Profession missingness = 0.01642392314843508\n",
      "Work_Experience missingness = 0.10009296560272699\n",
      "Spending_Score missingness = 0.0\n",
      "Family_Size missingness = 0.040904865199876045\n",
      "Var_1 missingness = 0.009296560272699102\n",
      "Segmentation missingness = 0.0\n",
      "\n",
      "missingness_drop_list:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "missingness_results_dict = get_missingness(train_df, missingness_threshold)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Set Up ML Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "non_ML_attr:\n",
      "index\n",
      "ID\n",
      "\n",
      "*****************************\n",
      "ML_attr:\n",
      "Gender\n",
      "Ever_Married\n",
      "Age\n",
      "Graduated\n",
      "Profession\n",
      "Work_Experience\n",
      "Spending_Score\n",
      "Family_Size\n",
      "Var_1\n",
      "Segmentation\n",
      "\n",
      "*****************************\n",
      "non_ml_attribute_list:\n",
      "['index', 'ID']\n"
     ]
    }
   ],
   "source": [
    "non_ml_attributes_results = separate_unique_columns(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_attributes_drop_list = [target_attr] # Drop the target to perform clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These attributes will be ignored by the machine learning algorithm:\n",
      "\t1. index\n",
      "\t2. ID\n",
      "\t3. Segmentation\n"
     ]
    }
   ],
   "source": [
    "ml_ignore_list = missingness_results_dict[\"missingness_drop_list\"] \\\n",
    "                 + non_ml_attributes_results[\"non_ML_attr\"] \\\n",
    "                 + ml_attributes_drop_list\n",
    "\n",
    "print(f\"These attributes will be ignored by the machine learning algorithm:\")\n",
    "for idx, attr in enumerate(ml_ignore_list):\n",
    "    print(f\"\\t{idx + 1}. {attr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All attributes in the train set have been accounted for.\n",
      "\n",
      "ML Ignore List:\n",
      "1. index\n",
      "2. ID\n",
      "3. Segmentation\n",
      "\n",
      "Numerical Attributes:\n",
      "1. Age\n",
      "2. Work_Experience\n",
      "3. Family_Size\n",
      "\n",
      "Nominal Attributes:\n",
      "1. Gender\n",
      "2. Ever_Married\n",
      "3. Graduated\n",
      "4. Profession\n",
      "5. Spending_Score\n",
      "6. Var_1\n",
      "\n",
      "Total Number of ML Attributes: 9\n"
     ]
    }
   ],
   "source": [
    "# Set the numerical attributes list\n",
    "numerical_attr = [\"Age\", \"Work_Experience\", \"Family_Size\"]\n",
    "\n",
    "# Set the nominal attributes list\n",
    "nominal_attr = [attr for attr in train_df.columns if attr not in numerical_attr and attr not in ml_ignore_list]\n",
    "\n",
    "# Confirm all attributes are accounted for\n",
    "assert (train_df.shape[1] == len(numerical_attr) + len(nominal_attr) + len(ml_ignore_list))\n",
    "print(f\"All attributes in the train set have been accounted for.\")\n",
    "print()\n",
    "\n",
    "print(\"ML Ignore List:\")\n",
    "for idx, attr in enumerate(ml_ignore_list):\n",
    "    print(f\"{idx + 1}. {attr}\")\n",
    "print()\n",
    "\n",
    "print(\"Numerical Attributes:\")\n",
    "for idx, attr in enumerate(numerical_attr):\n",
    "    print(f\"{idx + 1}. {attr}\")\n",
    "print()\n",
    "\n",
    "print(\"Nominal Attributes:\")\n",
    "for idx, attr in enumerate(nominal_attr):\n",
    "    print(f\"{idx + 1}. {attr}\")\n",
    "print()\n",
    "\n",
    "print(f\"Total Number of ML Attributes: {len(nominal_attr) + len(numerical_attr)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Inspect the Cardinality of Nominal Attributes  \n",
    "\n",
    "This will inform the choice of nominal attribute encoder.  \n",
    "\n",
    "```TargetEncoding``` can reduce the number of resultant encoded attributes compared to ```OneHotEncoding```.  \n",
    "This becomes an issue when the nominal attributes have a large number of unique values.  \n",
    "\n",
    "However, in the case of a ```multiclass``` target, ```TargetEncoder``` uses 1 versus all  \n",
    "approach to computing the probability estimates.  \n",
    "\n",
    "Resultingly, this may not result fewer dimensions than the\n",
    "```OneHotEncoder```.\n",
    "\n",
    "Both encoders will be explored in the context of clustering with ```DBSCAN```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender            2\n",
       "Ever_Married      2\n",
       "Graduated         2\n",
       "Profession        9\n",
       "Spending_Score    3\n",
       "Var_1             7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nominal_cols_df = train_df[nominal_attr]\n",
    "nominal_cols_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nominal Encoded Features Post OneHotEncoding:\n",
      "\tIf dropping one col per attribute: 19\n",
      "\tIf NOT dropping one col per attribute: 28\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of Nominal Encoded Features Post OneHotEncoding:\")\n",
    "print(f\"\\tIf dropping one col per attribute: {nominal_cols_df.nunique().sum() - len(nominal_attr)}\")\n",
    "print(f\"\\tIf NOT dropping one col per attribute: {nominal_cols_df.nunique().sum() + len(numerical_attr)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## **OneHotEncoder**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline(\n",
    "                            steps = [(\"imputer\", SimpleImputer()),\n",
    "                                     (\"scaler\", StandardScaler())]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_transformer = Pipeline(\n",
    "                        steps = [(\"imputer\", SimpleImputer(strategy = nominal_imputer_strategy)),\n",
    "                                 (\"ohe\", OneHotEncoder())] \n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "                        transformers = [(\"nominal\", nominal_transformer, nominal_attr),\n",
    "                                        (\"numerical\", numerical_transformer, numerical_attr)\n",
    "                                ]\n",
    "                        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Transformed Data ~ OneHotEncoder\n",
    "This shows the output of the data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfored_data = preprocessor.fit_transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.695320</td>\n",
       "      <td>1.942754</td>\n",
       "      <td>-1.227022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.703982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.560068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.635337</td>\n",
       "      <td>-0.513120</td>\n",
       "      <td>0.773838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.264401</td>\n",
       "      <td>-0.820105</td>\n",
       "      <td>2.107745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.935250</td>\n",
       "      <td>1.942754</td>\n",
       "      <td>-1.227022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6449</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.995233</td>\n",
       "      <td>1.635769</td>\n",
       "      <td>-1.227022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.395407</td>\n",
       "      <td>-0.820105</td>\n",
       "      <td>-0.560068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6451</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.995233</td>\n",
       "      <td>1.021801</td>\n",
       "      <td>2.107745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6452</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.055215</td>\n",
       "      <td>-0.820105</td>\n",
       "      <td>-0.560068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6453</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.395407</td>\n",
       "      <td>-0.820105</td>\n",
       "      <td>0.106885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6454 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9   ...   18   19   20  \\\n",
       "0     1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1     0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       "2     1.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       "3     1.0  0.0  0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4     1.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "6449  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "6450  0.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "6451  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0   \n",
       "6452  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "6453  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "       21   22   23   24        25        26        27  \n",
       "0     0.0  0.0  1.0  0.0 -0.695320  1.942754 -1.227022  \n",
       "1     0.0  0.0  1.0  0.0  1.703982  0.000000 -0.560068  \n",
       "2     0.0  0.0  1.0  0.0 -0.635337 -0.513120  0.773838  \n",
       "3     0.0  0.0  1.0  0.0  0.264401 -0.820105  2.107745  \n",
       "4     0.0  0.0  0.0  1.0 -0.935250  1.942754 -1.227022  \n",
       "...   ...  ...  ...  ...       ...       ...       ...  \n",
       "6449  0.0  0.0  1.0  0.0 -0.995233  1.635769 -1.227022  \n",
       "6450  0.0  0.0  1.0  0.0 -0.395407 -0.820105 -0.560068  \n",
       "6451  1.0  0.0  0.0  0.0 -0.995233  1.021801  2.107745  \n",
       "6452  0.0  0.0  1.0  0.0 -1.055215 -0.820105 -0.560068  \n",
       "6453  0.0  0.0  1.0  0.0 -0.395407 -0.820105  0.106885  \n",
       "\n",
       "[6454 rows x 28 columns]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(transfored_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of attrinutes after OneHotEncoding: 28\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of attrinutes after OneHotEncoding: {transfored_data.shape[1] + 1}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Gridsearch over ```DBSCAN``` with ```OneHotEncoder```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_row_dict_list = grid_search_DBSCAN(transfored_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = get_best_results(results_row_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>eps</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>validity_index</th>\n",
       "      <th>hopkins_stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>28.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.297498</td>\n",
       "      <td>0.241446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_components  n_clusters   eps  min_samples  validity_index  hopkins_stat\n",
       "20          28.0       140.0  0.85          5.0        0.297498      0.241446"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(best_results).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction with ```PCA``` ~ ```OneHotEncoding```\n",
    "This cell performs a gridsearch over DBSCAN hypers after dimenstionality reduction with PCA.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "n_components = [2,3,4,5,6,8,10,15]\n",
    "for n in n_components:\n",
    "    transfored_data_reduced = PCA(n_components = n).fit_transform(transfored_data)\n",
    "    results_row_dict_list = grid_search_DBSCAN(transfored_data_reduced)\n",
    "    best_results = get_best_results(results_row_dict_list)\n",
    "    results_list.append(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>eps</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>validity_index</th>\n",
       "      <th>hopkins_stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.563148</td>\n",
       "      <td>0.385945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.007134</td>\n",
       "      <td>0.291766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.035080</td>\n",
       "      <td>0.251862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.078419</td>\n",
       "      <td>0.221127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.086437</td>\n",
       "      <td>0.201093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_components  n_clusters   eps  min_samples  validity_index  hopkins_stat\n",
       "3            2.0         2.0  0.30         50.0       -0.563148      0.385945\n",
       "16           3.0         2.0  0.75         10.0       -0.007134      0.291766\n",
       "3            4.0         5.0  0.30         50.0        0.035080      0.251862\n",
       "14           5.0         5.0  0.60        100.0        0.078419      0.221127\n",
       "0            6.0       175.0  0.30          5.0        0.086437      0.201093"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## **Target Encoder**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Nominal Transformer ~ ```TargetEncoder```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap out OneHotEncoder() for TargetEncoder()\n",
    "nominal_transformer = Pipeline(\n",
    "                        steps = [(\"imputer\", SimpleImputer(strategy = nominal_imputer_strategy)),\n",
    "                                 (\"te\", TargetEncoder(target_type = \"multiclass\"))]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "                        transformers = [(\"nominal\", nominal_transformer, nominal_attr),\n",
    "                                        (\"numerical\", numerical_transformer, numerical_attr)\n",
    "                                ]\n",
    "                        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Transformed Data ~ ```TargetEncoder```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfored_data = preprocessor.fit_transform(train_df, train_df[target_attr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.243595</td>\n",
       "      <td>0.236872</td>\n",
       "      <td>0.254930</td>\n",
       "      <td>0.264601</td>\n",
       "      <td>0.236035</td>\n",
       "      <td>0.154651</td>\n",
       "      <td>0.118050</td>\n",
       "      <td>0.491204</td>\n",
       "      <td>0.248298</td>\n",
       "      <td>0.265294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188273</td>\n",
       "      <td>0.132800</td>\n",
       "      <td>0.405341</td>\n",
       "      <td>0.231111</td>\n",
       "      <td>0.236671</td>\n",
       "      <td>0.286454</td>\n",
       "      <td>0.245762</td>\n",
       "      <td>-0.695320</td>\n",
       "      <td>1.942754</td>\n",
       "      <td>-1.227022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.245147</td>\n",
       "      <td>0.224661</td>\n",
       "      <td>0.235086</td>\n",
       "      <td>0.295106</td>\n",
       "      <td>0.250079</td>\n",
       "      <td>0.281160</td>\n",
       "      <td>0.329089</td>\n",
       "      <td>0.139645</td>\n",
       "      <td>0.248298</td>\n",
       "      <td>0.265294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285662</td>\n",
       "      <td>0.462617</td>\n",
       "      <td>0.068626</td>\n",
       "      <td>0.231111</td>\n",
       "      <td>0.236671</td>\n",
       "      <td>0.286454</td>\n",
       "      <td>0.245762</td>\n",
       "      <td>1.703982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.560068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.246018</td>\n",
       "      <td>0.234701</td>\n",
       "      <td>0.253558</td>\n",
       "      <td>0.265723</td>\n",
       "      <td>0.241397</td>\n",
       "      <td>0.143910</td>\n",
       "      <td>0.124317</td>\n",
       "      <td>0.490316</td>\n",
       "      <td>0.246420</td>\n",
       "      <td>0.267426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181423</td>\n",
       "      <td>0.138163</td>\n",
       "      <td>0.408925</td>\n",
       "      <td>0.227237</td>\n",
       "      <td>0.236956</td>\n",
       "      <td>0.289405</td>\n",
       "      <td>0.246399</td>\n",
       "      <td>-0.635337</td>\n",
       "      <td>-0.513120</td>\n",
       "      <td>0.773838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.243934</td>\n",
       "      <td>0.236268</td>\n",
       "      <td>0.254997</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.241503</td>\n",
       "      <td>0.287127</td>\n",
       "      <td>0.326288</td>\n",
       "      <td>0.145058</td>\n",
       "      <td>0.243028</td>\n",
       "      <td>0.266001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296437</td>\n",
       "      <td>0.452701</td>\n",
       "      <td>0.080213</td>\n",
       "      <td>0.232637</td>\n",
       "      <td>0.234702</td>\n",
       "      <td>0.286123</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.264401</td>\n",
       "      <td>-0.820105</td>\n",
       "      <td>2.107745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.243595</td>\n",
       "      <td>0.236872</td>\n",
       "      <td>0.254930</td>\n",
       "      <td>0.264601</td>\n",
       "      <td>0.250079</td>\n",
       "      <td>0.281160</td>\n",
       "      <td>0.329089</td>\n",
       "      <td>0.139645</td>\n",
       "      <td>0.237950</td>\n",
       "      <td>0.171616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188273</td>\n",
       "      <td>0.132800</td>\n",
       "      <td>0.405341</td>\n",
       "      <td>0.251970</td>\n",
       "      <td>0.235727</td>\n",
       "      <td>0.219697</td>\n",
       "      <td>0.292587</td>\n",
       "      <td>-0.935250</td>\n",
       "      <td>1.942754</td>\n",
       "      <td>-1.227022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6449</th>\n",
       "      <td>0.243595</td>\n",
       "      <td>0.236872</td>\n",
       "      <td>0.254930</td>\n",
       "      <td>0.264601</td>\n",
       "      <td>0.236035</td>\n",
       "      <td>0.154651</td>\n",
       "      <td>0.118050</td>\n",
       "      <td>0.491204</td>\n",
       "      <td>0.237950</td>\n",
       "      <td>0.171616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188273</td>\n",
       "      <td>0.132800</td>\n",
       "      <td>0.405341</td>\n",
       "      <td>0.231111</td>\n",
       "      <td>0.236671</td>\n",
       "      <td>0.286454</td>\n",
       "      <td>0.245762</td>\n",
       "      <td>-0.995233</td>\n",
       "      <td>1.635769</td>\n",
       "      <td>-1.227022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>0.243069</td>\n",
       "      <td>0.226505</td>\n",
       "      <td>0.236229</td>\n",
       "      <td>0.294198</td>\n",
       "      <td>0.241397</td>\n",
       "      <td>0.143910</td>\n",
       "      <td>0.124317</td>\n",
       "      <td>0.490316</td>\n",
       "      <td>0.246420</td>\n",
       "      <td>0.267426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181423</td>\n",
       "      <td>0.138163</td>\n",
       "      <td>0.408925</td>\n",
       "      <td>0.227237</td>\n",
       "      <td>0.236956</td>\n",
       "      <td>0.289405</td>\n",
       "      <td>0.246399</td>\n",
       "      <td>-0.395407</td>\n",
       "      <td>-0.820105</td>\n",
       "      <td>-0.560068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6451</th>\n",
       "      <td>0.243934</td>\n",
       "      <td>0.236268</td>\n",
       "      <td>0.254997</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.249274</td>\n",
       "      <td>0.145159</td>\n",
       "      <td>0.122021</td>\n",
       "      <td>0.483486</td>\n",
       "      <td>0.247367</td>\n",
       "      <td>0.168447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182182</td>\n",
       "      <td>0.135523</td>\n",
       "      <td>0.400019</td>\n",
       "      <td>0.307809</td>\n",
       "      <td>0.228779</td>\n",
       "      <td>0.087867</td>\n",
       "      <td>0.375382</td>\n",
       "      <td>-0.995233</td>\n",
       "      <td>1.021801</td>\n",
       "      <td>2.107745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6452</th>\n",
       "      <td>0.243069</td>\n",
       "      <td>0.226505</td>\n",
       "      <td>0.236229</td>\n",
       "      <td>0.294198</td>\n",
       "      <td>0.241397</td>\n",
       "      <td>0.143910</td>\n",
       "      <td>0.124317</td>\n",
       "      <td>0.490316</td>\n",
       "      <td>0.240959</td>\n",
       "      <td>0.165452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181423</td>\n",
       "      <td>0.138163</td>\n",
       "      <td>0.408925</td>\n",
       "      <td>0.227237</td>\n",
       "      <td>0.236956</td>\n",
       "      <td>0.289405</td>\n",
       "      <td>0.246399</td>\n",
       "      <td>-1.055215</td>\n",
       "      <td>-0.820105</td>\n",
       "      <td>-0.560068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6453</th>\n",
       "      <td>0.246018</td>\n",
       "      <td>0.234701</td>\n",
       "      <td>0.253558</td>\n",
       "      <td>0.265723</td>\n",
       "      <td>0.241397</td>\n",
       "      <td>0.143910</td>\n",
       "      <td>0.124317</td>\n",
       "      <td>0.490316</td>\n",
       "      <td>0.246420</td>\n",
       "      <td>0.267426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181423</td>\n",
       "      <td>0.138163</td>\n",
       "      <td>0.408925</td>\n",
       "      <td>0.227237</td>\n",
       "      <td>0.236956</td>\n",
       "      <td>0.289405</td>\n",
       "      <td>0.246399</td>\n",
       "      <td>-0.395407</td>\n",
       "      <td>-0.820105</td>\n",
       "      <td>0.106885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6454 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.243595  0.236872  0.254930  0.264601  0.236035  0.154651  0.118050   \n",
       "1     0.245147  0.224661  0.235086  0.295106  0.250079  0.281160  0.329089   \n",
       "2     0.246018  0.234701  0.253558  0.265723  0.241397  0.143910  0.124317   \n",
       "3     0.243934  0.236268  0.254997  0.264800  0.241503  0.287127  0.326288   \n",
       "4     0.243595  0.236872  0.254930  0.264601  0.250079  0.281160  0.329089   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6449  0.243595  0.236872  0.254930  0.264601  0.236035  0.154651  0.118050   \n",
       "6450  0.243069  0.226505  0.236229  0.294198  0.241397  0.143910  0.124317   \n",
       "6451  0.243934  0.236268  0.254997  0.264800  0.249274  0.145159  0.122021   \n",
       "6452  0.243069  0.226505  0.236229  0.294198  0.241397  0.143910  0.124317   \n",
       "6453  0.246018  0.234701  0.253558  0.265723  0.241397  0.143910  0.124317   \n",
       "\n",
       "            7         8         9   ...        17        18        19  \\\n",
       "0     0.491204  0.248298  0.265294  ...  0.188273  0.132800  0.405341   \n",
       "1     0.139645  0.248298  0.265294  ...  0.285662  0.462617  0.068626   \n",
       "2     0.490316  0.246420  0.267426  ...  0.181423  0.138163  0.408925   \n",
       "3     0.145058  0.243028  0.266001  ...  0.296437  0.452701  0.080213   \n",
       "4     0.139645  0.237950  0.171616  ...  0.188273  0.132800  0.405341   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6449  0.491204  0.237950  0.171616  ...  0.188273  0.132800  0.405341   \n",
       "6450  0.490316  0.246420  0.267426  ...  0.181423  0.138163  0.408925   \n",
       "6451  0.483486  0.247367  0.168447  ...  0.182182  0.135523  0.400019   \n",
       "6452  0.490316  0.240959  0.165452  ...  0.181423  0.138163  0.408925   \n",
       "6453  0.490316  0.246420  0.267426  ...  0.181423  0.138163  0.408925   \n",
       "\n",
       "            20        21        22        23        24        25        26  \n",
       "0     0.231111  0.236671  0.286454  0.245762 -0.695320  1.942754 -1.227022  \n",
       "1     0.231111  0.236671  0.286454  0.245762  1.703982  0.000000 -0.560068  \n",
       "2     0.227237  0.236956  0.289405  0.246399 -0.635337 -0.513120  0.773838  \n",
       "3     0.232637  0.234702  0.286123  0.246536  0.264401 -0.820105  2.107745  \n",
       "4     0.251970  0.235727  0.219697  0.292587 -0.935250  1.942754 -1.227022  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6449  0.231111  0.236671  0.286454  0.245762 -0.995233  1.635769 -1.227022  \n",
       "6450  0.227237  0.236956  0.289405  0.246399 -0.395407 -0.820105 -0.560068  \n",
       "6451  0.307809  0.228779  0.087867  0.375382 -0.995233  1.021801  2.107745  \n",
       "6452  0.227237  0.236956  0.289405  0.246399 -1.055215 -0.820105 -0.560068  \n",
       "6453  0.227237  0.236956  0.289405  0.246399 -0.395407 -0.820105  0.106885  \n",
       "\n",
       "[6454 rows x 27 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(transfored_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The number of attributes after TargerEncoding: {transfored_data.shape[1] + 1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Gridsearch over ```DBSCAN``` with ```TargetEncoder```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_row_dict_list = grid_search_DBSCAN(transfored_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = get_best_results(results_row_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>eps</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>validity_index</th>\n",
       "      <th>hopkins_stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.143158</td>\n",
       "      <td>0.29256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_components  n_clusters  eps  min_samples  validity_index  hopkins_stat\n",
       "0          27.0       187.0  0.3          5.0        0.143158       0.29256"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(best_results).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction with ```PCA``` ~ ```TargetEncoder```  \n",
    "This cell performs a gridsearch over DBSCAN hypers after dimenstionality reduction with PCA.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nelsonfarrell/miniconda3/envs/conda_usml_env/lib/python3.12/site-packages/hdbscan/validity.py:33: RuntimeWarning: invalid value encountered in divide\n",
      "  result /= distance_matrix.shape[0] - 1\n",
      "/Users/nelsonfarrell/miniconda3/envs/conda_usml_env/lib/python3.12/site-packages/hdbscan/validity.py:33: RuntimeWarning: invalid value encountered in divide\n",
      "  result /= distance_matrix.shape[0] - 1\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "n_components = [2,3,4,5,6,8,10,15]\n",
    "for n in n_components:\n",
    "    transfored_data_reduced = PCA(n_components = n).fit_transform(transfored_data)\n",
    "    results_row_dict_list = grid_search_DBSCAN(transfored_data_reduced)\n",
    "    best_results = get_best_results(results_row_dict_list)\n",
    "    results_list.append(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>eps</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>validity_index</th>\n",
       "      <th>hopkins_stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.260176</td>\n",
       "      <td>0.282965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.297799</td>\n",
       "      <td>0.139627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.041375</td>\n",
       "      <td>0.186074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.043349</td>\n",
       "      <td>0.187294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.049009</td>\n",
       "      <td>0.195492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_components  n_clusters  eps  min_samples  validity_index  hopkins_stat\n",
       "0            2.0         2.0  0.3          5.0       -0.260176      0.282965\n",
       "2            3.0        11.0  0.3         20.0        0.297799      0.139627\n",
       "9            4.0         7.0  0.5        100.0        0.041375      0.186074\n",
       "14           5.0         6.0  0.6        100.0        0.043349      0.187294\n",
       "3            6.0         8.0  0.3         50.0        0.049009      0.195492"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_usml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da4cd8f0634bb089af8a080791cb3057e8ab3f308fd22cb7297c73023f3c5013"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
