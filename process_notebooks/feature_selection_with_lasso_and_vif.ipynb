{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43ba5672-c033-42b1-b88d-f109148b5f19",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6a4544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d74520",
   "metadata": {},
   "source": [
    "## set up for imports of .py modules by adding path to sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea617f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(os.getcwd())\n",
    "path = str(path)\n",
    "print(path)\n",
    "sys.path.insert(1, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594850d1-47d0-4d5f-b13d-4ea89277a4db",
   "metadata": {},
   "source": [
    "## import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb57fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.regression_utils as reg_utils\n",
    "import utils.sml_utils as sml_utils\n",
    "import utils.bin_class_utils as class_utils\n",
    "import utils.assign_and_lab_utils as al_utils\n",
    "import utils.assign_3_utils as assign_3_utils\n",
    "import utils.multi_colinearity_utils as mc_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912da942-33ca-4fd1-b11c-15a853f86baa",
   "metadata": {},
   "source": [
    "## helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d345b29-3d24-4edd-b18a-c93eac2fc42a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7372391d",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a0a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_milti_colinearity = True\n",
    "if with_milti_colinearity:\n",
    "    data_set = 'data_set_1'\n",
    "    path_to_data = 'data/synth_2_class_10000_0_55_0_45_15_6_4_1_4_0_0_0_5_w_noms.csv'\n",
    "    path_to_col_idx_shuffle_map = 'data/synth_2_class_10000_0_55_0_45_15_6_4_1_4_0_0_0_5_w_noms_col_idx_shuffle_map.pkl'\n",
    "else:\n",
    "    data_set = 'data_set_2'\n",
    "    path_to_data = 'data/synth_2_class_10000_0_55_0_45_15_6_0_0_9_0_0_0_5_w_noms.csv'\n",
    "    path_to_col_idx_shuffle_map = 'data/synth_2_class_10000_0_55_0_45_15_6_0_0_9_0_0_0_5_w_noms_col_idx_shuffle_map.pkl'\n",
    "\n",
    "# step 1 parameters - check for missingness in target vector\n",
    "target_attr = 'y'\n",
    "\n",
    "# step 2 parameters - train/test split\n",
    "test_size = 0.20\n",
    "train_test_split_random_state = 42\n",
    "\n",
    "# step 3 parameters - train/validation split\n",
    "\n",
    "# step 5 parameters - identify attributes with missingness above threshold\n",
    "missingness_threshold = 0.20\n",
    "\n",
    "# step 9 parameters - build a composite estimator\n",
    "target_encoder_random_state = 42\n",
    "\n",
    "# model selection parameters\n",
    "if with_milti_colinearity:\n",
    "    num_std = 1.0  # number of mse standard deviations to give up for a reduction in variables\n",
    "else:\n",
    "    num_std = 1.0  # number of mse standard deviations to give up for a reduction in variables\n",
    "\n",
    "model_type = 'LogisticRegressionCV'  # model specific cv from sklearn\n",
    "cv_folds = 5  # number of folds for model specific cv\n",
    "scoring='neg_log_loss'\n",
    "max_iter=100\n",
    "class_weight=None  # changing this could impact regularization\n",
    "\n",
    "penalty='l1'  # Cs describes the inverse of regularization strength\n",
    "\n",
    "if penalty == 'l1':\n",
    "    \n",
    "    l1_ratio_list = None\n",
    "    solver = 'saga'  # solver can be {‘liblinear’, ‘saga’}\n",
    "    cap_c_s = np.logspace(-4, 1, 50)  # l1 - Cs describes the inverse of regularization strength\n",
    "    \n",
    "elif penalty == 'l2':\n",
    "\n",
    "    l1_ratio_list = None\n",
    "    solver = 'saga'  # solver can be {‘lbfgs’, ‘liblinear’, ‘newton-cg’, ‘newton-cholesky’, ‘sag’, ‘saga’}\n",
    "    cap_c_s = np.logspace(-7, 1, 50)  # l2 - Cs describes the inverse of regularization strength\n",
    "    \n",
    "elif penalty == 'elasticnet':\n",
    "    \n",
    "    l1_ratio_list = [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1.0]  # values of l1 for ElasticNetCV to search over\n",
    "    solver = 'saga'  # solver can be {‘saga’}\n",
    "    \n",
    "else:\n",
    "    \n",
    "    sys.exit(f'penalty {penalty} is unrecognized')\n",
    "\n",
    "# understand nature of synthetic attributes\n",
    "col_idx_shuffle_map = False\n",
    "\n",
    "# check out attribute multi colinearity\n",
    "check_out_multi_colinearity = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d7251a",
   "metadata": {},
   "source": [
    "## set up to time script run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92dc12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b6299",
   "metadata": {},
   "source": [
    "## read in the data and get the size of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a453de0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_to_data)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d24fac-575f-4b86-b684-ca425ba39041",
   "metadata": {},
   "source": [
    "## out of pipeline preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e075d171-4e30-4f01-b1bf-5e3e134ffabe",
   "metadata": {},
   "source": [
    "### These operations cannot be completed in the scikit-learn pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a9ac6-8149-44dd-b930-6c21ce85c903",
   "metadata": {},
   "source": [
    "### They should be identified and passed on the the data engineer as tasks conducted during extract/transform/load (ETL) if the model goes to production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95889947-498b-4f4e-9fec-29dbbc3a2ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c4038d6-34e2-4a47-937f-4b656ad18d48",
   "metadata": {},
   "source": [
    "## 1. check for missingness in target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7cf8e4-85df-48ce-a60b-948a7705ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df.dropna(subset=target_attr)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542682cf-6eb8-4bc0-8426-58bf81d53345",
   "metadata": {},
   "source": [
    "## 2. label binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ef9bb4-99b1-4874-a4c8-29f24cfb48dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pd.api.types.infer_dtype(df[target_attr]) == 'string':\n",
    "    df, le_name_mapping = class_utils.label_binarize_binary(df, target_attr, print_results=True)\n",
    "else:\n",
    "    print(f'df[target_attr] is not a string attribute')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee95090-d432-42c4-ad3c-d5c987f1ea3f",
   "metadata": {},
   "source": [
    "## 3. train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114abf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cap_x_df, train_y_df = sml_utils.perform_the_train_test_split(df, test_size, train_test_split_random_state, val=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679d5e9e",
   "metadata": {},
   "source": [
    "## 4. train/validation split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead8178c-0a70-450e-83f4-8c4f92f91f58",
   "metadata": {},
   "source": [
    "### We will use the k-fold cross validation to select a model - no validation set is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1362509f",
   "metadata": {},
   "source": [
    "## check out the attribute types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce9c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cap_x_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a18266",
   "metadata": {},
   "source": [
    "## 5. identify attributes with  missingness above threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b5acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_dict = sml_utils.get_missingness(train_cap_x_df, missingness_threshold)\n",
    "missingness_drop_list = return_dict['missingness_drop_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8431b9e1-f0bd-40ef-90d4-0b41eadb0af3",
   "metadata": {},
   "source": [
    "## 6. identify non machine learning attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30628c8-900e-41fe-9b2d-632911310f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sml_utils.check_for_complete_unique_attrs(train_cap_x_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba0349-10e4-432b-97e7-bdc6603b6040",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ml_attr_list = ['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeaacc1-d918-453b-bf0a-d5ed17481c46",
   "metadata": {},
   "source": [
    "## 7. identify attributes to exclude from machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cap_x_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e520b-3cfc-407c-bf98-221fc4d072a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_attr_drop_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08cc3c8",
   "metadata": {},
   "source": [
    "## 8. establish machine learning attribute configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c59c34-ea97-4880-b67b-c54295d0db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_ignore_list = missingness_drop_list + non_ml_attr_list + ml_attr_drop_list\n",
    "ml_ignore_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578c1bdc-fd77-4cd8-9f18-e33b5c96e630",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cap_x_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67715159-6564-45a5-a6cc-df2fbf15dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cap_x_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5eecfa-6206-4f7a-bf09-c415cb099d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the remaining numerical attributes to be used in machine learning and enter them into the \n",
    "# numerical_attr list below.\n",
    "\n",
    "numerical_attr = []\n",
    "\n",
    "# identify the remaining nominal attributes to be used in machine learning and enter them into the \n",
    "# nominal_attr list below.\n",
    "\n",
    "nominal_attr = []\n",
    "\n",
    "assert(train_cap_x_df.shape[1] == len(ml_ignore_list) + len(nominal_attr) + len(numerical_attr))  # got them all?\n",
    "\n",
    "print(f'ml_ignore_list: {ml_ignore_list}')\n",
    "print(f'\\nnumerical_attr: {numerical_attr}')\n",
    "print(f'nominal_attr: {nominal_attr}')\n",
    "\n",
    "print(f'\\nnumber of machine learning attributes: {len(numerical_attr) + len(nominal_attr)}')\n",
    "print(f'\\nnumerical_attr and nominal_attr: {numerical_attr + nominal_attr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02f8049-2284-4b2f-ad84-d0483112cd4a",
   "metadata": {},
   "source": [
    "## 9. assess target attribute imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4dad40-187b-4453-9bd2-f02bd12fd1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_df[target_attr].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7ab5e4-48de-4c98-95ba-964175b36a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_df[target_attr].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b09f9e-22ae-4065-af86-877d12a3893c",
   "metadata": {},
   "source": [
    "## here we deviate from the binary classification flow - we are working to find a less complex model by variable selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e435860b-58e7-461a-aa7f-72a2ce88908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_dict = class_utils.model_specific_cv(\n",
    "    \n",
    "    cap_x_df=train_cap_x_df,\n",
    "    y_df=train_y_df,\n",
    "    nominal_attr=nominal_attr, \n",
    "    numerical_attr=numerical_attr, \n",
    "    \n",
    "    model_type=model_type,\n",
    "    \n",
    "    te_random_state=target_encoder_random_state, \n",
    "    \n",
    "    cap_c_s=cap_c_s, \n",
    "    cv_folds=cv_folds, \n",
    "    penalty=penalty, \n",
    "    scoring=scoring, \n",
    "    solver=solver, \n",
    "    max_iter=max_iter, \n",
    "    class_weight=class_weight, \n",
    "    l1_ratio_list=l1_ratio_list,\n",
    "    \n",
    "    num_std=num_std\n",
    ")\n",
    "\n",
    "preproc_cap_x_df = return_dict['preproc_cap_x_df']\n",
    "model_type = return_dict['model_type']\n",
    "fitted_model_cv = return_dict['fitted_model_cv']\n",
    "fitted_coef_dict = return_dict['fitted_coef_dict']\n",
    "new_fitted_coef_dict = return_dict['new_fitted_coef_dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2940c0-64c0-4761-b32b-c50ba405a451",
   "metadata": {},
   "source": [
    "## load the col_idx_shuffle_map to understand what types of attributes have had thier coef driven to 0 by Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab4274-e2e8-4ae5-982b-d6896e6642ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if col_idx_shuffle_map:\n",
    "    \n",
    "    with open(path_to_col_idx_shuffle_map, 'rb') as f:\n",
    "        col_idx_shuffle_map = pickle.load(f)\n",
    "    \n",
    "    \n",
    "    print(f'in col_idx_shuffle_map the key is the attributes data frame column index and the value is a tuple that describes the'\n",
    "          f' nature of the attribute\\n')\n",
    "    for attr, attr_nature in col_idx_shuffle_map.items():\n",
    "        print(f'attr: {attr}; attr_nature: {attr_nature}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23c8f98-3bcf-4828-a942-aa4ec0480dd7",
   "metadata": {},
   "source": [
    "## check out the nature of the attributes whose coef were driven to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc5e4e-108b-4621-9cc9-579220368ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if col_idx_shuffle_map:\n",
    "    \n",
    "    attr_to_drop = []\n",
    "    for attr, coef in new_fitted_coef_dict.items():\n",
    "        \n",
    "        if coef == 0:\n",
    "            \n",
    "            value = col_idx_shuffle_map[attr]\n",
    "            \n",
    "            print(f'attribute {attr} is a {value[2]} {value[1]} attribute with coef {new_fitted_coef_dict[attr]}')\n",
    "    \n",
    "            attr_to_drop.append(attr)\n",
    "    \n",
    "    for attr in attr_to_drop:\n",
    "        del new_fitted_coef_dict[attr]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4e9c1e-9d17-493e-9ba9-7f5ad1c7fa48",
   "metadata": {},
   "source": [
    "## check out the nature of the remaining attributes with non zero coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73a3f37-121e-4769-9de6-e5a57b6a7f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if col_idx_shuffle_map:\n",
    "    \n",
    "    for attr, coef in new_fitted_coef_dict.items():\n",
    "    \n",
    "        value = col_idx_shuffle_map[attr]\n",
    "        \n",
    "        print(f'attribute {attr} is a {value[2]} {value[1]} attribute with coef {new_fitted_coef_dict[attr]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c50e5d-3701-4e23-9992-6c84382b6ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if col_idx_shuffle_map:\n",
    "    \n",
    "    df_row_dict_list = []\n",
    "    for attr, coef in new_fitted_coef_dict.items():\n",
    "        df_row_dict_list.append(\n",
    "            {\n",
    "                'attr': attr,\n",
    "                'coef': coef,\n",
    "                'nature': col_idx_shuffle_map[attr][1]\n",
    "            }\n",
    "        )\n",
    "    plotting_df = pd.DataFrame(df_row_dict_list)\n",
    "    plotting_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef22e0a-758f-4b55-8359-6075972ab7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if col_idx_shuffle_map:\n",
    "    sns.histplot(plotting_df, x='coef', hue='nature')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aa6f29-3541-4eb4-a611-bdf63296ef8e",
   "metadata": {},
   "source": [
    "## check out multi colinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d3373-fb6b-4b95-b72d-e7d21a083bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_out_multi_colinearity and col_idx_shuffle_map:\n",
    "    a_num_attr_list = nominal_attr + numerical_attr\n",
    "    vifs_df = mc_utils.print_vifs(preproc_cap_x_df, a_num_attr_list, vif_inspection_threshold=2, ols_large_vifs=True)\n",
    "    vifs_df['nature'] = vifs_df.attribute.map(col_idx_shuffle_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec94d3-3417-4630-ae2e-3e93f34fcd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_out_multi_colinearity and col_idx_shuffle_map:\n",
    "    \n",
    "    print(vifs_df)\n",
    "    \n",
    "    correlation_matrix = preproc_cap_x_df.corr().round(2).values\n",
    "\n",
    "    triu_correlation_matrix = correlation_matrix[np.triu_indices(correlation_matrix.shape[0], k = 1)]\n",
    "\n",
    "    print()\n",
    "    flattened_corr_matrix = np.sort(triu_correlation_matrix.flatten())\n",
    "    print()\n",
    "    print(flattened_corr_matrix)\n",
    "    print()\n",
    "    print(flattened_corr_matrix.max())\n",
    "    print()\n",
    "    print(flattened_corr_matrix.min())\n",
    "\n",
    "    print()\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b81fbd6-558e-4f2c-85ac-5b10f3529456",
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_out_multi_colinearity and col_idx_shuffle_map and data_set == 'data_set_1':\n",
    "\n",
    "    temp_numerical_attr = numerical_attr.copy()\n",
    "    temp_numerical_attr.remove('attr_10') \n",
    "    temp_numerical_attr.remove('attr_14') \n",
    "    \n",
    "    return_dict = class_utils.model_specific_cv(\n",
    "        \n",
    "        cap_x_df=train_cap_x_df,\n",
    "        y_df=train_y_df,\n",
    "        nominal_attr=nominal_attr, \n",
    "        numerical_attr=temp_numerical_attr, \n",
    "        \n",
    "        model_type=model_type,\n",
    "        \n",
    "        te_random_state=target_encoder_random_state, \n",
    "        \n",
    "        cap_c_s=cap_c_s, \n",
    "        cv_folds=cv_folds, \n",
    "        penalty=penalty, \n",
    "        scoring=scoring, \n",
    "        solver=solver, \n",
    "        max_iter=max_iter, \n",
    "        class_weight=class_weight, \n",
    "        l1_ratio_list=l1_ratio_list,\n",
    "        \n",
    "        num_std=num_std\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321d9a6d",
   "metadata": {},
   "source": [
    "## check out script run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd9c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(f'script run time: {(end - start)/60} minutes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda_usml_env)",
   "language": "python",
   "name": "conda_usml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
