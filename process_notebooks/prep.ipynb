{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Data\n",
    "This notebook contains final project step $4$\n",
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up ```sys``` Path to Enable ```.py``` Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The working directory has been set to: /Users/nelsonfarrell/Documents/Northeastern/5220/final_project\n"
     ]
    }
   ],
   "source": [
    "path = Path.cwd()\n",
    "path_to_project_directory = path.parent\n",
    "sys.path.insert(1, str(path_to_project_directory))\n",
    "print(f\"The working directory has been set to: {str(path_to_project_directory)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.phase1_utils import * "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data_directory = \"/data/data_splits/\"\n",
    "train_data_file_name = \"train_df.csv\"\n",
    "target_attr = \"Segmentation\"\n",
    "missingness_threshold = 0.20\n",
    "nominal_imputer_strategy = \"most_frequent\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Read In Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df = pd.read_csv(str(path_to_project_directory) + path_to_data_directory + train_data_file_name)\n",
    "train_df = orig_df.copy()\n",
    "del orig_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>917</td>\n",
       "      <td>465905</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>32</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Artist</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3398</td>\n",
       "      <td>462903</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>72</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2045</td>\n",
       "      <td>467901</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>33</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8060</td>\n",
       "      <td>463613</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>48</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Artist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4604</td>\n",
       "      <td>459859</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>28</td>\n",
       "      <td>No</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_7</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      ID  Gender Ever_Married  Age Graduated     Profession  \\\n",
       "0    917  465905  Female           No   32       Yes         Artist   \n",
       "1   3398  462903    Male          Yes   72       Yes  Entertainment   \n",
       "2   2045  467901  Female           No   33       Yes  Entertainment   \n",
       "3   8060  463613  Female          Yes   48       Yes         Artist   \n",
       "4   4604  459859  Female          Yes   28        No         Doctor   \n",
       "\n",
       "   Work_Experience Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "0              9.0            Low          1.0  Cat_6            A  \n",
       "1              NaN        Average          2.0  Cat_6            B  \n",
       "2              1.0            Low          4.0  Cat_6            B  \n",
       "3              0.0        Average          6.0  Cat_6            A  \n",
       "4              9.0            Low          1.0  Cat_7            A  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Check for Missingness in the Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train set PRE to dropping rows where the target missing: (6454, 12)\n",
      "The shape of train set POST to dropping rows where the target missing: (6454, 12)\n",
      "Number of rows dropped: 0\n"
     ]
    }
   ],
   "source": [
    "num_rows_train_df_pre = train_df.shape[0]\n",
    "print(f\"The shape of train set PRE to dropping rows where the target missing: {train_df.shape}\")\n",
    "train_df = train_df.dropna(subset = target_attr)\n",
    "num_rows_train_df_post = train_df.shape[0]\n",
    "print(f\"The shape of train set POST to dropping rows where the target missing: {train_df.shape}\")\n",
    "print(f\"Number of rows dropped: {num_rows_train_df_pre - num_rows_train_df_post}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Perform Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This has already been performed\n",
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Perform Train Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will implemented later\n",
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Check Attribute ```dtypes```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                int64\n",
       "ID                   int64\n",
       "Gender              object\n",
       "Ever_Married        object\n",
       "Age                  int64\n",
       "Graduated           object\n",
       "Profession          object\n",
       "Work_Experience    float64\n",
       "Spending_Score      object\n",
       "Family_Size        float64\n",
       "Var_1               object\n",
       "Segmentation        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Identify Attributes Above ```Missingness``` Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index missingness = 0.0\n",
      "ID missingness = 0.0\n",
      "Gender missingness = 0.0\n",
      "Ever_Married missingness = 0.017198636504493336\n",
      "Age missingness = 0.0\n",
      "Graduated missingness = 0.00914161760148745\n",
      "Profession missingness = 0.01642392314843508\n",
      "Work_Experience missingness = 0.10009296560272699\n",
      "Spending_Score missingness = 0.0\n",
      "Family_Size missingness = 0.040904865199876045\n",
      "Var_1 missingness = 0.009296560272699102\n",
      "Segmentation missingness = 0.0\n",
      "\n",
      "missingness_drop_list:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "missingness_results_dict = get_missingness(train_df, missingness_threshold)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Identify Non-Machine Learning Attributes\n",
    "\n",
    "These attributes do not contain information that will benefit a machine learning algorithm.\n",
    "1. Identification columns\n",
    "2. Columns with very low variance, i.e., $0.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "non_ML_attr:\n",
      "index\n",
      "ID\n",
      "\n",
      "*****************************\n",
      "ML_attr:\n",
      "Gender\n",
      "Ever_Married\n",
      "Age\n",
      "Graduated\n",
      "Profession\n",
      "Work_Experience\n",
      "Spending_Score\n",
      "Family_Size\n",
      "Var_1\n",
      "Segmentation\n",
      "\n",
      "*****************************\n",
      "non_ml_attribute_list:\n",
      "['index', 'ID']\n"
     ]
    }
   ],
   "source": [
    "non_ml_attributes_results = separate_unique_columns(train_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Identify Attributes to Exclude from Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'ID', 'Gender', 'Ever_Married', 'Age', 'Graduated',\n",
       "       'Profession', 'Work_Experience', 'Spending_Score', 'Family_Size',\n",
       "       'Var_1', 'Segmentation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_attributes_drop_list = [] # None were identified"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Establish Machine Learning Attribute Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These attributes will be ignored by the machine learning algorithm:\n",
      "\t1. index\n",
      "\t2. ID\n"
     ]
    }
   ],
   "source": [
    "ml_ignore_list = missingness_results_dict[\"missingness_drop_list\"] \\\n",
    "                 + non_ml_attributes_results[\"non_ML_attr\"] \\\n",
    "                 + ml_attributes_drop_list\n",
    "\n",
    "print(f\"These attributes will be ignored by the machine learning algorithm:\")\n",
    "for idx, attr in enumerate(ml_ignore_list):\n",
    "    print(f\"\\t{idx + 1}. {attr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                int64\n",
       "ID                   int64\n",
       "Gender              object\n",
       "Ever_Married        object\n",
       "Age                  int64\n",
       "Graduated           object\n",
       "Profession          object\n",
       "Work_Experience    float64\n",
       "Spending_Score      object\n",
       "Family_Size        float64\n",
       "Var_1               object\n",
       "Segmentation        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All attributes in the train set have been accounted for.\n",
      "\n",
      "ML Ignore List:\n",
      "1. index\n",
      "2. ID\n",
      "\n",
      "Numerical Attributes:\n",
      "1. Age\n",
      "2. Work_Experience\n",
      "3. Family_Size\n",
      "\n",
      "Nominal Attributes:\n",
      "1. Gender\n",
      "2. Ever_Married\n",
      "3. Graduated\n",
      "4. Profession\n",
      "5. Spending_Score\n",
      "6. Var_1\n",
      "7. Segmentation\n",
      "\n",
      "Total Number of ML Attributes: 10\n"
     ]
    }
   ],
   "source": [
    "# Set the numerical attributes list\n",
    "numerical_attr = [\"Age\", \"Work_Experience\", \"Family_Size\"]\n",
    "\n",
    "# Set the nominal attributes list\n",
    "nominal_attr = [attr for attr in train_df.columns if attr not in numerical_attr and attr not in ml_ignore_list]\n",
    "\n",
    "# Confirm all attributes are accounted for\n",
    "assert (train_df.shape[1] == len(numerical_attr) + len(nominal_attr) + len(ml_ignore_list))\n",
    "print(f\"All attributes in the train set have been accounted for.\")\n",
    "print()\n",
    "\n",
    "print(\"ML Ignore List:\")\n",
    "for idx, attr in enumerate(ml_ignore_list):\n",
    "    print(f\"{idx + 1}. {attr}\")\n",
    "print()\n",
    "\n",
    "print(\"Numerical Attributes:\")\n",
    "for idx, attr in enumerate(numerical_attr):\n",
    "    print(f\"{idx + 1}. {attr}\")\n",
    "print()\n",
    "\n",
    "print(\"Nominal Attributes:\")\n",
    "for idx, attr in enumerate(nominal_attr):\n",
    "    print(f\"{idx + 1}. {attr}\")\n",
    "print()\n",
    "\n",
    "print(f\"Total Number of ML Attributes: {len(nominal_attr) + len(numerical_attr)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Build Composite Estimators"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Estimators Involved in Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be implemented later\n",
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical Transformer\n",
    "Transformations Performed:\n",
    "1. Imputation\n",
    "2. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline(\n",
    "                            steps = [(\"imputer\", SimpleImputer()),\n",
    "                                     (\"scaler\", StandardScaler())]\n",
    "                                )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nominal Transformer \n",
    "\n",
    "Transformations Performed:\n",
    "1. Imputation\n",
    "2. OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_transformer = Pipeline(\n",
    "                        steps = [(\"imputer\", SimpleImputer(strategy = nominal_imputer_strategy)),\n",
    "                                 (\"ohe\", OneHotEncoder())] \n",
    "                              )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "                        transformers = [(\"nominal\", nominal_transformer, nominal_attr),\n",
    "                                        \"numerical\", numerical_transformer, numerical_attr]\n",
    "                                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_usml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da4cd8f0634bb089af8a080791cb3057e8ab3f308fd22cb7297c73023f3c5013"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
