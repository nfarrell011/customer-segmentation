{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8db49d56-6f04-4e4f-8fb2-67c24f7e7112",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6a4544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime\n",
    "import pickle \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d74520",
   "metadata": {},
   "source": [
    "## set up for imports of .py modules by adding path to sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea617f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(os.getcwd())\n",
    "path = str(path)\n",
    "print(path)\n",
    "sys.path.insert(1, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594850d1-47d0-4d5f-b13d-4ea89277a4db",
   "metadata": {},
   "source": [
    "## import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb57fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.sml_utils as sml_utils\n",
    "import utils.bin_class_utils as class_utils\n",
    "import utils.glue_old_to_new as gotn\n",
    "import utils.assign_and_lab_utils as al_utils\n",
    "import utils.classification_utils as class_utils_2\n",
    "import utils.reg_model_selection_utils as reg_ms_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912da942-33ca-4fd1-b11c-15a853f86baa",
   "metadata": {},
   "source": [
    "## helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d345b29-3d24-4edd-b18a-c93eac2fc42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('no functions')  # all helpful functions should go in this cell to preserve the cell count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7372391d",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a0a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to data\n",
    "path_to_data = 'second_data_set/synth_2_class_5000_0_5_0_5_15_6_4_1_4_0_0_0_4_w_noms.csv'\n",
    "task = 'classification'\n",
    "\n",
    "# step 1 parameters - check for missingness in target vector\n",
    "target_attr = 'y'\n",
    "\n",
    "# step 2 parameters\n",
    "\n",
    "# step 3 parameters - train/test split\n",
    "test_size = 0.20\n",
    "train_test_split_random_state = 42\n",
    "\n",
    "# step 4 parameters - train/validation split\n",
    "train_validation_split = False\n",
    "val_size = 0.30\n",
    "train_validation_split_random_state = 42\n",
    "\n",
    "# step 4.25 parameters - ttrain/probability calibration split\n",
    "train_prob_cal_split = True  # used to calibrate classifier probability\n",
    "train_prob_cal_split_random_state = 42\n",
    "train_prob_cal_split_size = 0.20\n",
    "\n",
    "# step 4.5 parameters - train/classification threshold tuning split\n",
    "train_class_threshold_tune_split = True  # used to set the classification threshold\n",
    "train_class_threshold_tune_split_random_state = 42\n",
    "train_class_threshold_tune_split_size = 0.20\n",
    "\n",
    "# step 5 parameters - identify attributes with missingness above threshold\n",
    "missingness_threshold = 0.20\n",
    "\n",
    "# step 11 parameters - build a composite estimator\n",
    "sgd_class_random_state = 42\n",
    "target_encoder_random_state = 42\n",
    "class_weight = 'balanced'\n",
    "rf_random_state = 42\n",
    "dtc_stub_random_state = 42\n",
    "adaboost_random_state = 42\n",
    "svc_random_state = 42\n",
    "\n",
    "# step 12 parameters - model selection / model assessment parameters cross validation parameters\n",
    "scoring = ['neg_log_loss']  # must be in a list even if only one scoring metric\n",
    "kwargs = {'return_indices': False}  # if true the indices of the cross validation split are returned\n",
    "max_iter = 1000  # max number of epochs for SGDClassifier\n",
    "\n",
    "# step 12 parameters - maximal control k-fold cross validation splitter parameters\n",
    "kfold_n_splits = 10  # number of folds in k-fold cross validation\n",
    "kfold_shuffle = True\n",
    "kfold_random_state = 42\n",
    "\n",
    "# step 14 parameters - tune hyperparameters of short-listed composite estimators\n",
    "gs_cv_kfold_n_splits = 10\n",
    "gs_cv_kfold_shuffle = True\n",
    "gs_cv_kfold_random_state = 24\n",
    "show_all_params = True\n",
    "speed_up = False  # if True random stratified sample taken before GridSearchCV\n",
    "frac = 0.10  # fraction taken for speed up\n",
    "spd_up_random_state = 42  # speed up random state\n",
    "\n",
    "# step 16 parameters - calibrate the classifiers\n",
    "calibrate_classifiers = True\n",
    "frac_of_val_for_cal = 0.5  # 1 - frac to validate cal\n",
    "\n",
    "# step 18 parameters - model selection - configured for no model selection\n",
    "script_select = False  # default = False - True if you want to let the script select the model with the lowest log loss out of GridsearchCV\n",
    "hand_select = False  # default = False - if True you must select a model by hand and identify the model row index in grid_search_cv_results_df\n",
    "hand_select_index = None # do not change this line\n",
    "if hand_select:\n",
    "    hand_select_index = None  # default = None - if hand select enter best model index from grid_search_cv_results_df\n",
    "\n",
    "# step 19 - tune classification threshold\n",
    "classification_threshold = None  # default = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d7251a",
   "metadata": {},
   "source": [
    "## set up to time script run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92dc12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b6299",
   "metadata": {},
   "source": [
    "## read in the data and get the size of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a453de0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_to_data)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d24fac-575f-4b86-b684-ca425ba39041",
   "metadata": {},
   "source": [
    "## out of pipeline preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e075d171-4e30-4f01-b1bf-5e3e134ffabe",
   "metadata": {},
   "source": [
    "### These operations cannot be completed in the scikit-learn pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a9ac6-8149-44dd-b930-6c21ce85c903",
   "metadata": {},
   "source": [
    "### They should be identified and passed on the the data engineer as tasks conducted during extract/transform/load (ETL) if the model goes to production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4038d6-34e2-4a47-937f-4b656ad18d48",
   "metadata": {},
   "source": [
    "## 1. check for missingness in target vector and dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7cf8e4-85df-48ce-a60b-948a7705ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df.dropna(subset=target_attr)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548a0028-30f9-4f74-afe5-9130511b7969",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df.drop_duplicates()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611fa2d1-a646-4add-841c-72fdbfcf25ff",
   "metadata": {},
   "source": [
    "## 2. label binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b57f99-9714-4b01-ac26-eb68ad7e9559",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pd.api.types.infer_dtype(df[target_attr]) == 'string':\n",
    "    df, le_name_mapping = class_utils.label_binarize_binary(df, target_attr, print_results=True)\n",
    "else:\n",
    "    print(f'df[target_attr] is not a string attribute')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee95090-d432-42c4-ad3c-d5c987f1ea3f",
   "metadata": {},
   "source": [
    "## 3. train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ef6576-d58d-4316-bc5a-0536b728e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cap_x_df, train_y_df = \\\n",
    "    sml_utils.perform_the_train_test_split(\n",
    "    df, \n",
    "    test_size, \n",
    "    train_test_split_random_state, \n",
    "    val=False,\n",
    "    stratify=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679d5e9e",
   "metadata": {},
   "source": [
    "## 4. train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f543b-1e92-439f-99d9-9500d44c6350",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_validation_split:\n",
    "    train_cap_x_df, train_y_df = \\\n",
    "        sml_utils.perform_the_train_test_split(\n",
    "            pd.concat([train_cap_x_df, train_y_df], axis=1), \n",
    "            val_size, \n",
    "            train_validation_split_random_state, \n",
    "            val=True,\n",
    "            stratify=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1362509f",
   "metadata": {},
   "source": [
    "## 4.25 train / probability calibration split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce9c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_prob_cal_split:\n",
    "    train_cap_x_df, train_y_df = \\\n",
    "        sml_utils.perform_the_train_test_split(\n",
    "            pd.concat([train_cap_x_df, train_y_df], axis=1), \n",
    "            train_prob_cal_split_size, \n",
    "            train_prob_cal_split_random_state, \n",
    "            prob_cal=True,\n",
    "            stratify=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d856f2-2631-418b-9bfe-233589da1b15",
   "metadata": {},
   "source": [
    "## 4.5 train / classification threshold tuning split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1489e3-1e37-48d4-a436-d13fcb7f3d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_class_threshold_tune_split:\n",
    "    train_cap_x_df, train_y_df = \\\n",
    "        sml_utils.perform_the_train_test_split(\n",
    "            pd.concat([train_cap_x_df, train_y_df], axis=1), \n",
    "            train_class_threshold_tune_split_size, \n",
    "            train_class_threshold_tune_split_random_state, \n",
    "            classification_threshold=True,\n",
    "            stratify=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a18266",
   "metadata": {},
   "source": [
    "## 5. identify attributes with  missingness above threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b5acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_dict = sml_utils.get_missingness(train_cap_x_df, missingness_threshold)\n",
    "missingness_drop_list = return_dict['missingness_drop_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8431b9e1-f0bd-40ef-90d4-0b41eadb0af3",
   "metadata": {},
   "source": [
    "## 6. identify non machine learning attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e12cd3-f2d5-4ece-bae5-d47a54d247b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sml_utils.check_for_complete_unique_attrs(train_cap_x_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba0349-10e4-432b-97e7-bdc6603b6040",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ml_attr_list = ['attr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeaacc1-d918-453b-bf0a-d5ed17481c46",
   "metadata": {},
   "source": [
    "## 7. identify attributes to exclude from machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cap_x_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e520b-3cfc-407c-bf98-221fc4d072a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_attr_drop_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08cc3c8",
   "metadata": {},
   "source": [
    "## 8. establish machine learning attribute configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c59c34-ea97-4880-b67b-c54295d0db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_ignore_list = missingness_drop_list + non_ml_attr_list + ml_attr_drop_list\n",
    "ml_ignore_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578c1bdc-fd77-4cd8-9f18-e33b5c96e630",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cap_x_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78399c2-7b8e-4532-b906-35a609a5a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5eecfa-6206-4f7a-bf09-c415cb099d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the remaining numerical attributes to be used in machine learning and enter them into the \n",
    "# numerical_attr list below.\n",
    "\n",
    "numerical_attr = ['attr_1', 'attr_2', 'attr_4', 'attr_7', 'attr_8', 'attr_9', 'attr_11', 'attr_13', 'attr_15']\n",
    "\n",
    "# identify the remaining nominal attributes to be used in machine learning and enter them into the \n",
    "# nominal_attr list below.\n",
    "\n",
    "nominal_attr = ['attr_3', 'attr_6', 'attr_10', 'attr_12', 'attr_14']\n",
    "\n",
    "assert(train_cap_x_df.shape[1] == len(ml_ignore_list) + len(nominal_attr) + len(numerical_attr))  # got them all?\n",
    "\n",
    "print(f'ml_ignore_list: {ml_ignore_list}')\n",
    "print(f'\\nnumerical_attr: {numerical_attr}')\n",
    "print(f'nominal_attr: {nominal_attr}')\n",
    "\n",
    "print(f'\\nnumber of machine learning attributes: {len(numerical_attr) + len(nominal_attr)}')\n",
    "print(f'\\nnumerical_attr and nominal_attr: {numerical_attr + nominal_attr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485a8757-bc53-42ae-8215-0378180a700e",
   "metadata": {},
   "source": [
    "## 9. assess target attribute imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbd3d1c-f131-46c6-9e3d-bf91397dd654",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_df[target_attr].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95a0d01-16ae-4a79-89d2-3a05db70192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_df[target_attr].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad2d215-9ee7-4e64-a8a1-8979e7b4b006",
   "metadata": {},
   "source": [
    "## 10. steps to deal with target attribute imbalance if required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b173fe1-9e70-4d71-be62-9f01503c7a9a",
   "metadata": {},
   "source": [
    "To be completed later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b09f9e-22ae-4065-af86-877d12a3893c",
   "metadata": {},
   "source": [
    "## 11. build default composite estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fbcce2-a0b7-45de-8df9-cbf50f0f7ce8",
   "metadata": {},
   "source": [
    "### build a dictionary of default estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744b25e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_list = [\n",
    "\n",
    "    ('SGDClassifier', SGDClassifier(\n",
    "        loss='log_loss',  # 'hinge'\n",
    "        penalty='l2', \n",
    "        alpha=0.0001, \n",
    "        l1_ratio=0.15, \n",
    "        fit_intercept=True, \n",
    "        max_iter=max_iter, \n",
    "        tol=0.001, \n",
    "        shuffle=True, \n",
    "        verbose=0, \n",
    "        epsilon=0.1, \n",
    "        n_jobs=-1,  # None\n",
    "        random_state=sgd_class_random_state,  # None\n",
    "        learning_rate='optimal', \n",
    "        eta0=0.0, \n",
    "        power_t=0.5, \n",
    "        early_stopping=True,  # False,\n",
    "        validation_fraction=0.1, \n",
    "        n_iter_no_change=5, \n",
    "        class_weight=class_weight,  # None\n",
    "        warm_start=False, \n",
    "        average=False)\n",
    "    ),\n",
    "\n",
    "    ('RandomForestClassifier', RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        criterion='gini', \n",
    "        max_depth=None, \n",
    "        min_samples_split=2, \n",
    "        min_samples_leaf=1, \n",
    "        min_weight_fraction_leaf=0.0, \n",
    "        max_features='sqrt', \n",
    "        max_leaf_nodes=None, \n",
    "        min_impurity_decrease=0.0, \n",
    "        bootstrap=True, \n",
    "        oob_score=False, \n",
    "        n_jobs=-1,  # None, \n",
    "        random_state=rf_random_state,  # None\n",
    "        verbose=0, \n",
    "        warm_start=False, \n",
    "        class_weight=class_weight,  # None\n",
    "        ccp_alpha=0.0, \n",
    "        max_samples=None, \n",
    "        monotonic_cst=None)\n",
    "    ),\n",
    "\n",
    "    ('AdaBoostClassifier', AdaBoostClassifier(\n",
    "        estimator=DecisionTreeClassifier(\n",
    "            criterion='gini', \n",
    "            splitter='best', \n",
    "            max_depth=1,  # None\n",
    "            min_samples_split=2, \n",
    "            min_samples_leaf=1, \n",
    "            min_weight_fraction_leaf=0.0, \n",
    "            max_features=None, \n",
    "            random_state=dtc_stub_random_state,  # None\n",
    "            max_leaf_nodes=None, \n",
    "            min_impurity_decrease=0.0, \n",
    "            class_weight=class_weight, \n",
    "            ccp_alpha=0.0, \n",
    "            monotonic_cst=None\n",
    "        ),\n",
    "        n_estimators=50, \n",
    "        learning_rate=1.0, \n",
    "        algorithm='SAMME',\n",
    "        random_state=adaboost_random_state)  # None\n",
    "    )\n",
    "\n",
    "]\n",
    "\n",
    "estimator_dict = {\n",
    "    \n",
    "    estimators_list[0][0]: estimators_list[0][1],  # SGDClassifier\n",
    "\n",
    "    # estimators_list[1][0]: estimators_list[1][1],  # RandomForestClassifier\n",
    "    \n",
    "    # estimators_list[2][0]: estimators_list[2][1],  # AdaBoostClassifier\n",
    "\n",
    "    # 'VotingClassifier': VotingClassifier(\n",
    "    #     estimators=[\n",
    "    #         (estimators_list[0][0], estimators_list[0][1]),  # SGDClassifier\n",
    "    #         (estimators_list[1][0], estimators_list[1][1]),  # RandomForestClassifier\n",
    "    #         (estimators_list[2][0], estimators_list[2][1])  # AdaBoostClassifier\n",
    "    #     ],\n",
    "    #     voting='soft',  # 'hard'\n",
    "    #     weights=[1.0, 1.0, 1.0],  # None, \n",
    "    #     n_jobs=-1,  # None\n",
    "    #     flatten_transform=True, \n",
    "    #     verbose=False\n",
    "    # )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c5cb2b-583b-44a5-9217-4eba3ea892be",
   "metadata": {},
   "source": [
    "### build a preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1622ce-bd17-4913-bbea-a91c753e9627",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer()),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb90df6-493f-4e8a-9bb9-502e4594fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy='most_frequent')),\n",
    "        (\"target_encoder\", TargetEncoder(\n",
    "                    categories='auto', \n",
    "                    target_type='binary', \n",
    "                    smooth='auto', \n",
    "                    cv=5, \n",
    "                    shuffle=True, \n",
    "                    random_state=target_encoder_random_state\n",
    "                )\n",
    "        ),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c46d52e-a3ce-480c-882f-cccc60df7708",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('nominal', nominal_transformer, nominal_attr),\n",
    "            ('numerical', numerical_transformer, numerical_attr)\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee0c13a",
   "metadata": {},
   "source": [
    "## 12. survey (fit and evaluate with cost function and ranking metrics)  default composite estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f3c2e-a9a8-4171-8442-e1ea9bcf5d13",
   "metadata": {},
   "source": [
    "### survey candidate default models by fitting them on the whole train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dd1605-06e9-49e5-9ce8-5b86db4ff2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_dict = sml_utils.model_survey_fit(preprocessor, estimator_dict, train_cap_x_df, train_y_df)\n",
    "trained_estimator_dict = return_dict['trained_estimator_dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7d3194-faf2-4073-ade1-78d76d919d34",
   "metadata": {},
   "source": [
    "### estimate the test error rate using k-fold cross validation - use KFold splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e5319d-e1cb-430d-b4ad-96e8140d245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the maximal control k-fold cross validation splitter\n",
    "splitter = StratifiedKFold(\n",
    "    n_splits=kfold_n_splits,\n",
    "    shuffle=kfold_shuffle,\n",
    "    random_state=kfold_random_state\n",
    ")\n",
    "splitter.get_n_splits(train_cap_x_df, train_y_df[target_attr])\n",
    "\n",
    "# perform cross validation on models\n",
    "sml_utils.model_survey_cross_val_and_analysis(\n",
    "    preprocessor, \n",
    "    estimator_dict, \n",
    "    train_cap_x_df, \n",
    "    train_y_df, \n",
    "    scoring, \n",
    "    splitter, \n",
    "    target_attr, \n",
    "    trained_estimator_dict, \n",
    "    task=task,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4110db2-1d5b-4706-9d22-ae6624444f06",
   "metadata": {},
   "source": [
    "### get the ranking metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05132f9-2a48-46ed-89d4-0d42099cdb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the maximal control k-fold cross validation splitter\n",
    "splitter = StratifiedKFold(\n",
    "    n_splits=kfold_n_splits,\n",
    "    shuffle=kfold_shuffle,\n",
    "    random_state=kfold_random_state\n",
    ")\n",
    "splitter.get_n_splits(train_cap_x_df, train_y_df[target_attr])\n",
    "\n",
    "# perform cross validation on models\n",
    "sml_utils.model_survey_cross_val_and_analysis(\n",
    "    preprocessor=preprocessor, \n",
    "    estimator_dict=estimator_dict, \n",
    "    train_cap_x_df=train_cap_x_df, \n",
    "    train_y_df=train_y_df, \n",
    "    scoring=['average_precision', 'roc_auc'], \n",
    "    splitter=splitter, \n",
    "    target_attr=target_attr, \n",
    "    trained_estimator_dict=trained_estimator_dict, \n",
    "    task=task,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67220555-becc-4a4d-8c4a-d0ca550b850d",
   "metadata": {},
   "source": [
    "## 13. short list default composite estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1a4452-017e-41c2-9c20-beb6d119650c",
   "metadata": {},
   "source": [
    "### We are going to promote all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcac6294-5912-4de7-acc2-38873afe642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2420f9b9-a04b-45b9-b6ae-7c69c910eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del estimator_dict['ElasticNet']\n",
    "\n",
    "# estimator_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84616cac-25e7-46e9-9cf0-ce815c9b3c18",
   "metadata": {},
   "source": [
    "## 14. tune hyperparameters of short-listed composite estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a755e38-0ab8-48fe-8f80-3a1316d9ebfd",
   "metadata": {},
   "source": [
    "### demonstrate the numpy logspace function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c6658-1aef-4267-b5ba-6d48e479df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.logspace(0.7, 2, num=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe33a23-1891-477b-834a-2b3f7989aec3",
   "metadata": {},
   "source": [
    "### demonstrate the numpy arange function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689396bf-1166-4d6e-bef1-c919f94408ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.arange(0.0, 1.1, step=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df90d53d-96f6-4679-ab33-8fefd7f416e1",
   "metadata": {},
   "source": [
    "### demonstrate python range function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4a82d4-86dd-4d82-acf2-3144f0d5b464",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(5, 96, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0361b2bb-b294-4b17-a82f-a728329f58c4",
   "metadata": {},
   "source": [
    "### set up the hyperparameter space for the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af48c12a-552a-4e31-a570-ed49a972ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_param_grid = {\n",
    "    'preprocessor__numerical__imputer__strategy': ['mean', 'median'],\n",
    "    'preprocessor__nominal__target_encoder__smooth': ['auto']\n",
    "}\n",
    "\n",
    "sgd_classifier_param_grid = preproc_param_grid | {\n",
    "\n",
    "    'estimator__penalty': [],\n",
    "    'estimator__alpha': [],\n",
    "    'estimator__l1_ratio': []\n",
    "    \n",
    "}\n",
    "\n",
    "rf_classifier_param_grid = preproc_param_grid | {\n",
    "    \n",
    "    'estimator__n_estimators': [],\n",
    "    'estimator__max_depth': [],\n",
    "    'estimator__min_samples_leaf': [],\n",
    "    'estimator__max_features': [],\n",
    "    'estimator__max_samples': []\n",
    "    \n",
    "}\n",
    "\n",
    "adaboost_classifier_param_grid = preproc_param_grid | {\n",
    "    \n",
    "    'estimator__estimator__max_depth': [],\n",
    "    'estimator__estimator__min_samples_leaf': [],\n",
    "    'estimator__n_estimators': [],\n",
    "    'estimator__learning_rate': []\n",
    "    \n",
    "}\n",
    "\n",
    "voting_classifier_param_grid = preproc_param_grid | {\n",
    "    \n",
    "    'estimator__SGDClassifier__penalty': [],  \n",
    "    'estimator__SGDClassifier__alpha': [],  \n",
    "    'estimator__SGDClassifier__l1_ratio': [],  \n",
    "    \n",
    "    'estimator__RandomForestClassifier__n_estimators': [],  \n",
    "    'estimator__RandomForestClassifier__max_depth': [],  \n",
    "    'estimator__RandomForestClassifier__min_samples_leaf': [],  \n",
    "    'estimator__RandomForestClassifier__max_features': [],  \n",
    "    'estimator__RandomForestClassifier__max_samples': [],  #\n",
    "\n",
    "    'estimator__AdaBoostClassifier__estimator__max_depth': [],\n",
    "    'estimator__AdaBoostClassifier__estimator__min_samples_leaf': [],\n",
    "    'estimator__AdaBoostClassifier__n_estimators': [],\n",
    "    'estimator__AdaBoostClassifier__learning_rate': []\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'SGDClassifier': sgd_classifier_param_grid,\n",
    "    'RandomForestClassifier': rf_classifier_param_grid,\n",
    "    'AdaBoostClassifier': adaboost_classifier_param_grid,\n",
    "    'VotingClassifier': voting_classifier_param_grid\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ca0e6-6231-42f5-8014-248a82d2ba24",
   "metadata": {},
   "source": [
    "### perform the grid search cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63b0208-30f1-4b98-9bf2-9209ca646e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the maximal control k-fold cross validation splitter\n",
    "splitter = StratifiedKFold(\n",
    "    n_splits=gs_cv_kfold_n_splits,\n",
    "    shuffle=gs_cv_kfold_shuffle,\n",
    "    random_state=gs_cv_kfold_random_state\n",
    ")\n",
    "splitter.get_n_splits(train_cap_x_df, train_y_df[target_attr])\n",
    "\n",
    "# collect grid seach cv results here\n",
    "tuned_estimator_dict = {}\n",
    "\n",
    "if speed_up:\n",
    "    print(f'before speed_up train_cap_x_df.shape: {train_cap_x_df.shape}')\n",
    "    print(f'before speed_up train_y_df.value_counts():\\n{train_y_df.value_counts()}')\n",
    "    train_cap_x_df, train_y_df = sml_utils.sample_data_objects_for_speed_up(train_cap_x_df, train_y_df, frac=frac, \n",
    "                                                                            random_state=spd_up_random_state)\n",
    "    print(f'\\nafter speed_up train_cap_x_df.shape: {train_cap_x_df.shape}')\n",
    "    print(f'after speed_up train_y_df.value_counts():\\n{train_y_df.value_counts()}')\n",
    "\n",
    "for estimator_name, estimator in estimator_dict.items():\n",
    "    \n",
    "    print(f'\\n{estimator_name}')\n",
    "\n",
    "    composite_estimator = \\\n",
    "    Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('estimator', estimator)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    grid_search_cv = GridSearchCV(\n",
    "        estimator=composite_estimator, \n",
    "        param_grid=param_grids[estimator_name], \n",
    "        scoring=scoring,  # in preparation for multi metric evaluation scoring variable is a list\n",
    "        n_jobs=None, \n",
    "        refit=scoring[0],  # when scoring is a list we must specify which scoring method is used for the refit\n",
    "        cv=splitter, \n",
    "        verbose=0, \n",
    "        pre_dispatch='2*n_jobs', \n",
    "        error_score=np.nan, \n",
    "        return_train_score=True\n",
    "    )\n",
    "    gs_start = time.time()\n",
    "    grid_search_cv.fit(train_cap_x_df, train_y_df.values.ravel())\n",
    "    gs_end = time.time()\n",
    "    print(f'   GridSearchCV run time for {estimator_name}: {(gs_end - gs_start)/60:.3f} minutes')\n",
    "        \n",
    "    tuned_estimator_dict[estimator_name] = grid_search_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b174e08-c1ca-48b8-a150-ec773a45d216",
   "metadata": {},
   "source": [
    "### check out the flexibility plots of the grid search cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7a61b7-e277-4d40-9d78-73f77c1fb275",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_survey_results_df = pd.DataFrame()\n",
    "for estimator_name, grid_search_cv in tuned_estimator_dict.items():\n",
    "    print('\\n\\n')\n",
    "    return_dict = sml_utils.plot_flexibility(\n",
    "        grid_search_cv=grid_search_cv,\n",
    "        estimator_name=estimator_name,\n",
    "        scoring=scoring\n",
    "    )\n",
    "    results_df = return_dict['results_df']\n",
    "    results_df['estimator_name'] = estimator_name\n",
    "    results_df = results_df[['estimator_name'] + [attr for attr in results_df if attr not in ['estimator_name']]]\n",
    "    gs_survey_results_df = pd.concat([gs_survey_results_df, results_df], axis=0)\n",
    "\n",
    "gs_survey_results_df = gs_survey_results_df.sort_values(['score', 'best_test_score'])\n",
    "gs_survey_results_df = gs_survey_results_df.reset_index(drop=True)\n",
    "gs_survey_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce43bbc-74b7-4530-8dbd-5242baf080cf",
   "metadata": {},
   "source": [
    "### alternative model selection - use gs_survey_results_df to pick an alternative model from the grid serach and add it to tuned_estimator_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3cb90-eaa4-4a51-8707-c30e1d98dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_alt_model = False\n",
    "add_alternative_model_to_flow = False\n",
    "\n",
    "if explore_alt_model:\n",
    "    \n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    \n",
    "    return_dict = reg_ms_utils.alternative_model_selection(\n",
    "        trained_estimator_dict, \n",
    "        tuned_estimator_dict,\n",
    "        train_cap_x_df, \n",
    "        train_y_df,\n",
    "        gs_survey_results_df,\n",
    "        scoring,\n",
    "        param_grids,\n",
    "        demo_reg_flow=False,  # True = demo flow and False = develop algo to get alternative model\n",
    "        estimator='AdaBoostClassifier',  # the estimator you want an alternative choice for\n",
    "        frac_count=0.2,  # frac_count * number of grid points = how many gridpoints in a row the train and test bands are separated\n",
    "        num_std=1.0,  # specifies the width of the train and test bands in units of std dev on flex plot\n",
    "        man_flex_plot_index=250, # None,  # None  # = None means algo used - if integer then you must visually inspect flex plot and specify flex_index to get the hyperparameters of the model you want\n",
    "        add_alternative_model_to_flow=add_alternative_model_to_flow\n",
    "    )\n",
    "\n",
    "    if add_alternative_model_to_flow:\n",
    "        tuned_estimator_dict = return_dict['tuned_estimator_dict']\n",
    "        gs_survey_results_df = return_dict['gs_survey_results_df']\n",
    "        param_grids = return_dict['param_grids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45030e5-36c1-4efd-9c10-5c65686af864",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_survey_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfb8260-ecf5-4909-a52b-39ae7570db58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs_survey_results_df = gs_survey_results_df.loc[gs_survey_results_df.estimator_name != 'AlternativeRandomForestClassifier', :]\n",
    "# gs_survey_results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8dd9bd93-041b-4627-86e0-c44985266ce7",
   "metadata": {},
   "source": [
    "## 15. evaluate (cost function and ranking metrics) tuned composite estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ba2396-d67b-4e47-a8a1-12a1b9dcd203",
   "metadata": {},
   "source": [
    "### use cross validation for model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111ddbb9-113c-4896-aa4a-7a2692645f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the maximal control k-fold cross validation splitter\n",
    "splitter = StratifiedKFold(\n",
    "    n_splits=kfold_n_splits,\n",
    "    shuffle=kfold_shuffle,\n",
    "    random_state=kfold_random_state\n",
    ")\n",
    "splitter.get_n_splits(train_cap_x_df, train_y_df[target_attr])\n",
    "\n",
    "# perform cross validation on models\n",
    "sml_utils.model_tuning_cross_val_and_analysis(\n",
    "    tuned_estimator_dict, \n",
    "    train_cap_x_df, \n",
    "    train_y_df, \n",
    "    scoring, \n",
    "    splitter, \n",
    "    target_attr,\n",
    "    task=task\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58402c07-c167-4bc7-a1b6-9a858f792d39",
   "metadata": {},
   "source": [
    "### get the ranking metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750d6190-e2b1-45e3-97a2-aeca2a6ac6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the maximal control k-fold cross validation splitter\n",
    "splitter = StratifiedKFold(\n",
    "    n_splits=kfold_n_splits,\n",
    "    shuffle=kfold_shuffle,\n",
    "    random_state=kfold_random_state\n",
    ")\n",
    "splitter.get_n_splits(train_cap_x_df, train_y_df[target_attr])\n",
    "\n",
    "# perform cross validation on models\n",
    "return_dict = sml_utils.model_tuning_cross_val_and_analysis(\n",
    "    tuned_estimator_dict=tuned_estimator_dict, \n",
    "    train_cap_x_df=train_cap_x_df, \n",
    "    train_y_df=train_y_df, \n",
    "    scoring=['average_precision', 'roc_auc'], \n",
    "    splitter=splitter, \n",
    "    target_attr=target_attr,\n",
    "    task=task,\n",
    "    return_=True\n",
    ")\n",
    "tuned_model_ranking_cv_scores_grouped_df = return_dict['cv_scores_grouped_df']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bff4b5b-daec-471c-a244-83726fd28a66",
   "metadata": {},
   "source": [
    "### check out the best estimator hyperparameters for each estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200116ba-cbc6-43d7-a1f6-e649199e225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best hyperparameters for each estimator\\n')\n",
    "\n",
    "for index, row in gs_survey_results_df.iterrows():\n",
    "    \n",
    "    print(f'\\nestimator_name: {row['estimator_name']}; score: {row['score']}')\n",
    "    \n",
    "    param_grids_ = param_grids[row['estimator_name']]\n",
    "    for hyperparameter_name, hyperparameter_value in row['grid_search_cv'].best_params_.items():\n",
    "\n",
    "        if len(param_grids_[hyperparameter_name]) > 1 and not show_all_params:  #  and only_show_searched_params:  # only check the hyperparameter you are varing\n",
    "            print(f'   hyperparameter_name: {hyperparameter_name}; hyperparameter_value: {hyperparameter_value}')\n",
    "        elif show_all_params:\n",
    "            print(f'   hyperparameter_name: {hyperparameter_name}; hyperparameter_value: {hyperparameter_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893c0868-843f-47f9-b7c3-05ac35e76472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the minimum test score from the GridSeachCV\n",
    "\n",
    "min_test_score = gs_survey_results_df.best_test_score.min()\n",
    "print(f'\\nMinimum test score from GridSearchCV: {min_test_score}')\n",
    "\n",
    "# get the name of the estimator with the minimum test score\n",
    "estimator_name = gs_survey_results_df.loc[gs_survey_results_df['best_test_score'] == min_test_score, 'estimator_name'].iloc[0]\n",
    "print(f'\\nThe estimator with minimum test score from GridSearchCV is considered the best model. It is: {estimator_name}')\n",
    "\n",
    "# get the best estimator\n",
    "best_model_name = gs_survey_results_df.loc[gs_survey_results_df['best_test_score'] == min_test_score, 'estimator_name'].values[0]\n",
    "best_model = gs_survey_results_df.loc[gs_survey_results_df['best_test_score'] == min_test_score, 'grid_search_cv'].values[0].best_estimator_\n",
    "\n",
    "print(f'\\nNote that the best estimator from a GridSearchCV is not necessarily the best model.\\n'\n",
    "      f'\\nThe best model will come from a GridSearchCV that was conducted with a parameter grid\\n'\n",
    "      f'that covered the range of parameters to give the best model.\\n'\n",
    "      f'\\nTypically several GridSearchCV runs are required to assure yourself the the range of\\n'\n",
    "      f'parameters can give the best model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c460d1-87d0-42a5-84fb-bc887b5358da",
   "metadata": {},
   "source": [
    "### evaluate tuned composite estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad127a89-d4c0-408b-8055-f4b8ed56d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss_best_model_on_train_set = log_loss(train_y_df, best_model.predict_proba(train_cap_x_df))\n",
    "\n",
    "print(f'best_model is the trained estimator that performed the best in GridSearchCV.\\n'\n",
    "      f'\\nIt was trained on the whole train set using the hyperparameter combination\\n'\n",
    "      f'that gave the lowest estimate of test error rate in cross validation.\\n'\n",
    "      f'\\nThe log loss of the best_model when prediction on the whole train set is {log_loss_best_model_on_train_set}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a3692d-eb75-475a-90f6-590ef82ec072",
   "metadata": {},
   "source": [
    "## beyond this point we will start using portions of an older code base so this is cell is dedicated to meeting the requirments of that code base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0ae2c3-fa13-46e0-8ea7-d62249083490",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv_results_df = gotn.prep_gs_survey_results_df_for_calibration(gs_survey_results_df, tuned_model_ranking_cv_scores_grouped_df)\n",
    "grid_search_cv_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb101b-aad1-4790-b836-085e424b072e",
   "metadata": {},
   "source": [
    "## 16. calibrate classifier if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f6558-9672-46ff-a00c-631c472565bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_classifiers:\n",
    "    \n",
    "    # class_eval_dict:\n",
    "    #    key = name of function in classification_utils.py\n",
    "    #    value = [bool, function kwargs]  bool = True then call function\n",
    "    print_plots = False\n",
    "    binary = True\n",
    "    class_eval_dict={\n",
    "        'binary': binary,\n",
    "        'scoring': 'average_precision',\n",
    "        'get_precision_recall_curves': [True, \n",
    "                                            {\n",
    "                                                'print_prc': print_plots, \n",
    "                                                'print_prd': print_plots,\n",
    "                                            }\n",
    "                                       ],\n",
    "        'get_roc_curve': [True, \n",
    "                              {\n",
    "                                  'print_roc': print_plots,\n",
    "                              }\n",
    "                         ]\n",
    "    }\n",
    "\n",
    "    # load the data for probability calibration\n",
    "    prob_cal_set_df = pd.read_csv('prob_cal_set_df.csv').set_index(keys='index')\n",
    "    prob_cal_set_df.index.name = None\n",
    "    prob_cal_set_cap_x_df, prob_cal_set_y_df = prob_cal_set_df.iloc[:, :-1], prob_cal_set_df.iloc[:, -1].to_frame()\n",
    "    cal_count = int(frac_of_val_for_cal * prob_cal_set_cap_x_df.shape[0])\n",
    "    cal_val_count = prob_cal_set_cap_x_df.shape[0] - cal_count\n",
    "\n",
    "    # calibrate the probability\n",
    "    cal_grid_search_cv_results_df = al_utils.calibrate_estimators(\n",
    "        estimator_names=grid_search_cv_results_df.estimator.to_list(),  # list(tuned_estimator_dict.keys()), \n",
    "        grid_search_cv_results_df=grid_search_cv_results_df,\n",
    "        cal_cap_x_df=prob_cal_set_cap_x_df.iloc[:cal_count,:],  # calibrate on unseen data\n",
    "        cal_y_df=prob_cal_set_y_df.iloc[:cal_count,:],  # calibrate on unseen data\n",
    "        calibration_data_set_name='first half of prob_cal_set_df', \n",
    "        validation_cap_x_df=prob_cal_set_cap_x_df.iloc[cal_count:,:],  # use unseen data to validate calibration \n",
    "        validation_y_df=prob_cal_set_y_df.iloc[cal_count:,:],  # use unseen data to validate calibration \n",
    "        validation_data_set_name='second half of prob_cal_set_df',\n",
    "        class_eval_dict=class_eval_dict,\n",
    "        model_selection_stage='tuned', \n",
    "        method='isotonic',  # 'sigmoid' or 'isotonic'\n",
    "        ensemble=True\n",
    "    )\n",
    "\n",
    "    # clean up estimator names\n",
    "    estimator_names = al_utils.get_estimator_names_helper(\n",
    "        grid_search_cv_results_df, \n",
    "        cal_grid_search_cv_results_df\n",
    "    )\n",
    "\n",
    "    # add probability calibration data to the data frame\n",
    "    grid_search_cv_results_df = pd.concat([cal_grid_search_cv_results_df, grid_search_cv_results_df], axis=0)\n",
    "\n",
    "del prob_cal_set_df, prob_cal_set_cap_x_df, prob_cal_set_y_df\n",
    "\n",
    "grid_search_cv_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c5df7b-1570-4b85-8387-048a0ecc3781",
   "metadata": {},
   "source": [
    "## the resampling method in old code base is validation data set method. in the new code base we use k-fold cross validation. we will replace the numbers from the old method with numbers from the new method for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12afe8dc-0019-491b-8d25-58f0736c5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the maximal control k-fold cross validation splitter\n",
    "splitter = StratifiedKFold(\n",
    "    n_splits=kfold_n_splits,\n",
    "    shuffle=kfold_shuffle,\n",
    "    random_state=kfold_random_state\n",
    ")\n",
    "splitter.get_n_splits(train_cap_x_df, train_y_df[target_attr])\n",
    "\n",
    "# perform cross validation on models\n",
    "return_dict = sml_utils.model_tuning_cross_val_and_analysis(\n",
    "    tuned_estimator_dict=dict(zip(grid_search_cv_results_df.estimator, grid_search_cv_results_df.best_estimator)),\n",
    "    train_cap_x_df=train_cap_x_df, \n",
    "    train_y_df=train_y_df, \n",
    "    scoring=['average_precision', 'roc_auc'], \n",
    "    splitter=splitter, \n",
    "    target_attr=target_attr,\n",
    "    task=task,\n",
    "    return_=True\n",
    ")\n",
    "tuned_model_ranking_cv_scores_grouped_df = return_dict['cv_scores_grouped_df']\n",
    "\n",
    "grid_search_cv_results_df = gotn.add_ave_precision_and_roc_auc(grid_search_cv_results_df, tuned_model_ranking_cv_scores_grouped_df)\n",
    "grid_search_cv_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55334204-5874-4a5e-917b-cd5d88efcd9c",
   "metadata": {},
   "source": [
    "## 17. check for false discoveries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c92df9d-e82c-4405-8483-0ca655aec9d1",
   "metadata": {},
   "source": [
    "### shuffle the target and do cross validation to understand if we have a real or false discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bb45cf-f41d-401d-aac4-e037b099a111",
   "metadata": {},
   "outputs": [],
   "source": [
    "sml_utils.check_for_false_discoveries(\n",
    "    tuned_estimator_dict, \n",
    "    train_cap_x_df, \n",
    "    train_y_df, \n",
    "    scoring, \n",
    "    splitter, \n",
    "    target_attr, \n",
    "    shuffle_target=True,\n",
    "    shuffle_target_random_state=42, \n",
    "    gs_survey_results_df=gs_survey_results_df,\n",
    "    task=task\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac7930e-864c-4f7e-9d49-12ad97be5c2e",
   "metadata": {},
   "source": [
    "## 18. select a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d0071-634e-4138-a5e8-606fe8b58cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_estimator = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6b79ef-f12e-4965-ac69-d0b3f950ea35",
   "metadata": {},
   "source": [
    "### You can let the script select the best model by setting composite_estimator = best_model below. This will select the model with the lowest log loss coming out of GridSearchCV. This is done in cell 43."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72990f0b-cefe-4dff-a42c-fca0fe6f16ad",
   "metadata": {},
   "source": [
    "### Or you can hand select the model you want to promote from the list of models below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09863c42-4d9d-4e8f-a0bd-1a92d1197965",
   "metadata": {},
   "source": [
    "### This is helpful if you want to select a model based on average precision or roc auc. It is also helpful if you want to select a model that has had its probability calibrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf83601d-6304-48cc-95f6-9c30969adcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5909c2ba-71a1-4986-8dd9-103395c0f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'currently the best model name based on log loss coming out of GridSearchCV is {best_model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b952f28-535e-4dd7-8560-a6e9746f6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if script_select:\n",
    "    print(f'you have opted for using the best_model and best_model_name assigned in cell 47 using log loss of uncalibrated '\n",
    "          f'model')\n",
    "elif hand_select:\n",
    "    if hand_select_index is None or hand_select_index not in grid_search_cv_results_df.index:\n",
    "        sys.exit(f'{hand_select_index} is not a valid index - go to cell 5 line 69 and enter a valid grid_search_cv_results_df'\n",
    "                 f' index to indicate the model you want to select')\n",
    "    else:\n",
    "        best_model_name = grid_search_cv_results_df.loc[hand_select_index, 'estimator']\n",
    "        best_model = grid_search_cv_results_df.loc[hand_select_index, 'best_estimator']\n",
    "else:\n",
    "    sys.exit(f'go to cell 5 lines 65 to 69 to set up model selection')\n",
    "\n",
    "print(f'\\nthe best model name is {best_model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8629907-1e51-4b8b-964e-bd516aaaafce",
   "metadata": {},
   "source": [
    "## 19. tune classification threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783f92b6-5d1f-4fb3-9a36-952dbb478916",
   "metadata": {},
   "source": [
    "### scan over classification thresholds and pick the threshold that minimizes the most costly errors - recall or precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed191f13-12b7-48d3-9a5e-56154d16c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_thresh_set_df = pd.read_csv('class_thresh_set_df.csv').set_index(keys='index')\n",
    "class_thresh_set_df.index.name = None\n",
    "class_thresh_set_cap_x_df, class_thresh_set_y_df = class_thresh_set_df.iloc[:, :-1], class_thresh_set_df.iloc[:, -1].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc3835c-5c7d-4dc5-b6f5-66cb5f4a441f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_threshold_list = np.arange(0, 1.1, 0.1)\n",
    "thresh_class_perf_dict = \\\n",
    "    class_utils_2.class_thresh_metrics_class_perf_assess_binary(\n",
    "        best_model_name=best_model_name, \n",
    "        estimator_names=estimator_names, \n",
    "        grid_search_cv_results_df=grid_search_cv_results_df, \n",
    "        cap_x_df=class_thresh_set_cap_x_df, \n",
    "        y_df=class_thresh_set_y_df, \n",
    "        class_threshold_list=class_threshold_list, \n",
    "        cvs_compute=False, \n",
    "        cvs_print=False, \n",
    "        data_set_name='class_thresh_set_df', \n",
    "        model_selection_stage='tuned'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531fb776-93ae-48bc-b8b2-f9633e7997dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_threshold_list = np.arange(0, 1.01, 0.01)\n",
    "class_utils_2.plot_errors_as_a_function_of_classification_threshold(\n",
    "    best_model_name=best_model_name, \n",
    "    estimator_names=estimator_names, \n",
    "    grid_search_cv_results_df=grid_search_cv_results_df, \n",
    "    cap_x_df=class_thresh_set_cap_x_df, \n",
    "    y_df=class_thresh_set_y_df, \n",
    "    class_threshold_list=class_threshold_list, \n",
    "    data_set_name='class_thresh_set_df',\n",
    "    model_selection_stage='tuned'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e805df82-2055-4d00-abac-64eb6ff85926",
   "metadata": {},
   "source": [
    "### use bootstrapping to understand how metrics will vary for future data sets from the same data generation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352cab73-07e1-4067-a219-5f3a59fd82d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if classification_threshold is None:\n",
    "    sys.exit(f'{classification_threshold} is not a valid classification threshold - go to cell 5 line 72 to set a classification threshold')\n",
    "else:\n",
    "    print(f'the classification threshold is {classification_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed095f4-53a6-4549-94ce-32d915c88bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_utils_2.precision_recall_bootstrap_no_refit_binary(\n",
    "    best_model_name=best_model_name,\n",
    "    estimator_names=estimator_names, \n",
    "    grid_search_cv_results_df=grid_search_cv_results_df,\n",
    "    cap_x_df=class_thresh_set_cap_x_df,\n",
    "    y_df=class_thresh_set_y_df, \n",
    "    n_bootstrap=20,\n",
    "    data_set_name='class_thresh_set_df', \n",
    "    model_selection_stage='tuned',\n",
    "    classification_threshold=classification_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165adefb-056f-4355-81c4-e31defee6472",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_utils_2.roc_curve_bootstrap_no_refit_binary(\n",
    "    best_model_name=best_model_name,\n",
    "    estimator_names=estimator_names, \n",
    "    grid_search_cv_results_df=grid_search_cv_results_df, \n",
    "    cap_x_df=class_thresh_set_cap_x_df, \n",
    "    y_df=class_thresh_set_y_df, \n",
    "    n_bootstrap=20,\n",
    "    data_set_name='class_thresh_set_df', \n",
    "    model_selection_stage='tuned',\n",
    "    classification_threshold=classification_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1c5b30-d9df-4acc-8112-6cdd91779cbc",
   "metadata": {},
   "source": [
    "### take a final look at this models performance when tuned to the classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e12f92-22de-46c0-bec5-3c68944f8487",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_perf_dict = class_utils_2.classification_performance(\n",
    "    trained_classifier=best_model, \n",
    "    cap_x_df=class_thresh_set_cap_x_df, \n",
    "    y_df=class_thresh_set_y_df.values.ravel(), \n",
    "    classification_threshold=classification_threshold,\n",
    "    binary=True,\n",
    "    # https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "    cvs_scoring_dict={\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': 'precision',\n",
    "        'recall': 'recall',\n",
    "        'f1': 'f1'\n",
    "    },\n",
    "    cr_digits=4,\n",
    "    cr_print=True,  # print classification report\n",
    "    cm_print=True,  # print confusion matrix\n",
    "    cvs_compute=False,  # compute cross_val_scores (classification threshold = 0.5 always)\n",
    "    cvs_print=True,  # print cross_val_scores (classification threshold = 0.5 always) - ignored if cvs_compute=False\n",
    "    prc_print=True,  # print precision and recall curves as a function of classification threshold\n",
    "    prd_print=True,  # print precision recall curves\n",
    "    roc_print=True,  # print roc curve\n",
    "    data_set_name='class_thresh_set_df', \n",
    "    model_selection_stage='tuned'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b41fc-76d4-4db1-b781-9d2eece84aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "del class_thresh_set_df, class_thresh_set_cap_x_df, class_thresh_set_y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cc6cee-3a0f-49c0-94d5-e7dfba796306",
   "metadata": {},
   "source": [
    "## serialize model and classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07345ee6-d3f6-4197-a6f0-2ccf9a330129",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "date_time_prefix = str(now).replace('-', '_').replace(' ', '_').replace(':', '_').replace('.', '_')[:-4]\n",
    "\n",
    "date_time_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97370d50-87b2-4185-8814-63879931e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator_file_name = date_time_prefix + '_model' + '.pkl'\n",
    "\n",
    "best_estimator_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e00e6c-073f-4320-ad53-79b78073327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_estimator = \\\n",
    "#     grid_search_cv_results_df.loc[grid_search_cv_results_df.estimator == best_model, 'best_estimator'].iloc[0]\n",
    "\n",
    "model_dict = {\n",
    "    'classification_threshold': classification_threshold,\n",
    "    'best_model_name': best_model_name,\n",
    "    'best_model': best_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d54735-6311-473e-ba15-37a20db8d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(best_estimator_file_name, 'wb') as f:\n",
    "    pickle.dump(model_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68c99c7-4c7b-4d13-bbed-7bd36e67e205",
   "metadata": {},
   "source": [
    "## evaluate model on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aec8da0-f4ac-4871-9e25-9dd1db657a67",
   "metadata": {},
   "source": [
    "This should be done in an independent notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321d9a6d",
   "metadata": {},
   "source": [
    "## check out script run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd9c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(f'script run time: {(end - start)/60} minutes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda_usml_env)",
   "language": "python",
   "name": "conda_usml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
